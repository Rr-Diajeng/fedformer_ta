{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be3c273b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='TEMPERATURE_WITHLSTM_MS', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/temperature/', data_path='temperature_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=24, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=18, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : TEMPERATURE_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 37.00979518890381\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.2994408 | val_loss=0.0593647 val_MAE=0.1893594 |\n",
      "Validation loss decreased (inf --> 0.059365).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 35.561508893966675\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.2116464 | val_loss=0.0824517 val_MAE=0.2254905 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 35.068212032318115\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.1774603 | val_loss=0.0899623 val_MAE=0.2391132 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 35.113295793533325\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.1632951 | val_loss=0.0683385 val_MAE=0.1984544 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.08782122284173965, mae:0.2265772521495819\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:0.6712641497928395, mae:0.6264166808388545\n",
      "CSV saved → ./results/TEMPERATURE_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=18, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : TEMPERATURE_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 34.38962531089783\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.3072135 | val_loss=0.0948649 val_MAE=0.2458782 |\n",
      "Validation loss decreased (inf --> 0.094865).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 32.73646521568298\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.2076974 | val_loss=0.0652461 val_MAE=0.1983531 |\n",
      "Validation loss decreased (0.094865 --> 0.065246).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 33.12632417678833\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.1796078 | val_loss=0.0606817 val_MAE=0.1893482 |\n",
      "Validation loss decreased (0.065246 --> 0.060682).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 32.9014835357666\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.1616617 | val_loss=0.0872563 val_MAE=0.2324014 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 36.19526648521423\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.1524499 | val_loss=0.0682693 val_MAE=0.1980958 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 35.050111293792725\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.1474007 | val_loss=0.0740057 val_MAE=0.2084375 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.09160669893026352, mae:0.22851654887199402\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:0.7001985516703696, mae:0.6317782103134355\n",
      "CSV saved → ./results/TEMPERATURE_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=18, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : TEMPERATURE_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 33.065536975860596\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.3050494 | val_loss=0.0705598 val_MAE=0.2060419 |\n",
      "Validation loss decreased (inf --> 0.070560).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 33.17511439323425\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.2082767 | val_loss=0.1233497 val_MAE=0.2870718 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 33.20077133178711\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.1765869 | val_loss=0.0746492 val_MAE=0.2100639 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 32.81321668624878\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.1610196 | val_loss=0.1120009 val_MAE=0.2584625 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.11028844118118286, mae:0.25516951084136963\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:0.8429929482592117, mae:0.7054654370817874\n",
      "CSV saved → ./results/TEMPERATURE_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (17304, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --root_path ./dataset/temperature/ --data_path temperature_dataset.csv --task_id TEMPERATURE_WITHLSTM_MS --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 24 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98cd2dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='GHI_WITHLSTM_MS', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/ghi/', data_path='ghi_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=24, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=18, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : GHI_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 33.15585660934448\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.4252257 | val_loss=0.2940910 val_MAE=0.3804989 |\n",
      "Validation loss decreased (inf --> 0.294091).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 32.11594867706299\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.3177367 | val_loss=0.2748607 val_MAE=0.3777759 |\n",
      "Validation loss decreased (0.294091 --> 0.274861).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 32.143051624298096\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.2958148 | val_loss=0.2530819 val_MAE=0.3392836 |\n",
      "Validation loss decreased (0.274861 --> 0.253082).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 34.26232147216797\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.2831077 | val_loss=0.2369749 val_MAE=0.3273548 |\n",
      "Validation loss decreased (0.253082 --> 0.236975).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 32.334980487823486\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.2759520 | val_loss=0.2472321 val_MAE=0.3276368 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 32.62590837478638\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.2708691 | val_loss=0.2575363 val_MAE=0.3320101 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 32.34027290344238\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.2697003 | val_loss=0.2513982 val_MAE=0.3281593 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : GHI_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.30249983072280884, mae:0.3590765595436096\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:19955.203204444362, mae:92.22583909734232\n",
      "CSV saved → ./results/GHI_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=18, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : GHI_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 33.169495582580566\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.4571180 | val_loss=0.2947477 val_MAE=0.3805561 |\n",
      "Validation loss decreased (inf --> 0.294748).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 32.51217293739319\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.3172224 | val_loss=0.2357442 val_MAE=0.3296557 |\n",
      "Validation loss decreased (0.294748 --> 0.235744).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 32.2038676738739\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.3009677 | val_loss=0.2414221 val_MAE=0.3236508 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 32.9346137046814\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.2837367 | val_loss=0.2488005 val_MAE=0.3293606 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 32.398595094680786\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.2766785 | val_loss=0.2710262 val_MAE=0.3407300 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : GHI_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.3091515004634857, mae:0.3677962124347687\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:20393.99811249871, mae:94.46540546530349\n",
      "CSV saved → ./results/GHI_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=18, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : GHI_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 32.13430666923523\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.4418290 | val_loss=0.3075232 val_MAE=0.3944842 |\n",
      "Validation loss decreased (inf --> 0.307523).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 32.42520475387573\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.3197081 | val_loss=0.2674704 val_MAE=0.3538332 |\n",
      "Validation loss decreased (0.307523 --> 0.267470).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 32.15341782569885\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.2940023 | val_loss=0.2347354 val_MAE=0.3254815 |\n",
      "Validation loss decreased (0.267470 --> 0.234735).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 32.966554403305054\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.2818558 | val_loss=0.2271633 val_MAE=0.3180043 |\n",
      "Validation loss decreased (0.234735 --> 0.227163).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 32.27429556846619\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.2765177 | val_loss=0.2466597 val_MAE=0.3259917 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 32.65301012992859\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.2709858 | val_loss=0.2540442 val_MAE=0.3295156 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 32.26237487792969\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.2681027 | val_loss=0.2448877 val_MAE=0.3236003 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : GHI_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.31561052799224854, mae:0.36644554138183594\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:20820.086442832424, mae:94.11850020367993\n",
      "CSV saved → ./results/GHI_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (17304, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --root_path ./dataset/ghi/ --data_path ghi_dataset.csv --task_id GHI_WITHLSTM_MS --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 24 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2a3f8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='KW_WITHLSTM_MS', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/kw/', data_path='kw_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=24, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=18, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : KW_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 32.547264099121094\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.3432067 | val_loss=0.2202189 val_MAE=0.3746954 |\n",
      "Validation loss decreased (inf --> 0.220219).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 31.442412853240967\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.2056387 | val_loss=0.1605552 val_MAE=0.3094834 |\n",
      "Validation loss decreased (0.220219 --> 0.160555).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 32.325719118118286\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.1706872 | val_loss=0.1744053 val_MAE=0.3269429 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 31.52892541885376\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.1558070 | val_loss=0.1537897 val_MAE=0.3038475 |\n",
      "Validation loss decreased (0.160555 --> 0.153790).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 31.572033405303955\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.1484291 | val_loss=0.1496832 val_MAE=0.2995046 |\n",
      "Validation loss decreased (0.153790 --> 0.149683).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 31.57969045639038\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.1438829 | val_loss=0.1503125 val_MAE=0.2993930 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 31.849976778030396\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.1424960 | val_loss=0.1467572 val_MAE=0.2953867 |\n",
      "Validation loss decreased (0.149683 --> 0.146757).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 8 cost time: 31.92573380470276\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 8, Steps 66 | train_loss=0.1402046 | val_loss=0.1489056 val_MAE=0.2985189 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 9 cost time: 32.07733988761902\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 9, Steps 66 | train_loss=0.1393345 | val_loss=0.1490258 val_MAE=0.2984642 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 10 cost time: 31.735715627670288\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 10, Steps 66 | train_loss=0.1397245 | val_loss=0.1497136 val_MAE=0.2993421 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : KW_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.15736784040927887, mae:0.3009350895881653\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:2420.872766253909, mae:37.32508705087235\n",
      "CSV saved → ./results/KW_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=18, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : KW_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 31.53569269180298\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.3105012 | val_loss=0.2149514 val_MAE=0.3670103 |\n",
      "Validation loss decreased (inf --> 0.214951).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 31.82980489730835\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.1989360 | val_loss=0.1983914 val_MAE=0.3521469 |\n",
      "Validation loss decreased (0.214951 --> 0.198391).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 31.591569662094116\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.1698609 | val_loss=0.1661515 val_MAE=0.3193232 |\n",
      "Validation loss decreased (0.198391 --> 0.166152).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 31.96150302886963\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.1523977 | val_loss=0.1670029 val_MAE=0.3216984 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 31.501781702041626\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.1442409 | val_loss=0.1516940 val_MAE=0.3026355 |\n",
      "Validation loss decreased (0.166152 --> 0.151694).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 31.37971258163452\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.1409293 | val_loss=0.1560125 val_MAE=0.3080884 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 31.271879196166992\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.1377379 | val_loss=0.1540584 val_MAE=0.3064992 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 8 cost time: 31.740242958068848\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 8, Steps 66 | train_loss=0.1375678 | val_loss=0.1517422 val_MAE=0.3033853 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : KW_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.16052880883216858, mae:0.3072231113910675\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:2469.499584196498, mae:38.10499329555771\n",
      "CSV saved → ./results/KW_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=18, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : KW_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 31.85177707672119\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.3490733 | val_loss=0.1947229 val_MAE=0.3523788 |\n",
      "Validation loss decreased (inf --> 0.194723).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 31.68405818939209\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.2010968 | val_loss=0.2138149 val_MAE=0.3735376 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 31.90463924407959\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.1716536 | val_loss=0.1861971 val_MAE=0.3365517 |\n",
      "Validation loss decreased (0.194723 --> 0.186197).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 32.217928886413574\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.1587137 | val_loss=0.1648394 val_MAE=0.3176486 |\n",
      "Validation loss decreased (0.186197 --> 0.164839).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 32.371479749679565\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.1482182 | val_loss=0.1522124 val_MAE=0.3029784 |\n",
      "Validation loss decreased (0.164839 --> 0.152212).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 32.48536682128906\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.1446986 | val_loss=0.1547889 val_MAE=0.3056233 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 32.86955952644348\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.1428573 | val_loss=0.1561019 val_MAE=0.3083857 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 8 cost time: 32.31225037574768\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 8, Steps 66 | train_loss=0.1418372 | val_loss=0.1529846 val_MAE=0.3042282 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : KW_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.16462023556232452, mae:0.30944380164146423\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:2532.4403841570697, mae:38.38042465174658\n",
      "CSV saved → ./results/KW_WITHLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (17304, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --root_path ./dataset/kw/ --data_path kw_dataset.csv --task_id KW_WITHLSTM_MS --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 24 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b183c3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='TEMPERATURE_WITHLSTM_MS_Wavelets', model='FEDformer', version='Wavelets', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/temperature/', data_path='temperature_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=24, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : TEMPERATURE_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 39.96302127838135\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.3689439 | val_loss=0.0531467 val_MAE=0.1800477 |\n",
      "Validation loss decreased (inf --> 0.053147).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 39.3909375667572\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.1822721 | val_loss=0.0822726 val_MAE=0.2287091 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 39.0776469707489\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.1512340 | val_loss=0.0859461 val_MAE=0.2316554 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 40.29798150062561\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.1306730 | val_loss=0.0798440 val_MAE=0.2198673 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.08397436887025833, mae:0.2229783833026886\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:0.6418606534151003, mae:0.6164668959491002\n",
      "CSV saved → ./results/TEMPERATURE_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : TEMPERATURE_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 39.540444135665894\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.3660856 | val_loss=0.0800952 val_MAE=0.2282393 |\n",
      "Validation loss decreased (inf --> 0.080095).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 39.75242781639099\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.1762696 | val_loss=0.1177351 val_MAE=0.2736589 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 39.543779134750366\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.1428906 | val_loss=0.0819334 val_MAE=0.2237882 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 39.2132830619812\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.1199829 | val_loss=0.0822648 val_MAE=0.2206532 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.13515014946460724, mae:0.28857457637786865\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:1.0330242783858354, mae:0.7978202834288398\n",
      "CSV saved → ./results/TEMPERATURE_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : TEMPERATURE_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 39.20632743835449\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.3574177 | val_loss=0.0536090 val_MAE=0.1819702 |\n",
      "Validation loss decreased (inf --> 0.053609).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 39.23875856399536\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.1823688 | val_loss=0.0767871 val_MAE=0.2182184 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 39.259313106536865\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.1460754 | val_loss=0.0756722 val_MAE=0.2142139 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 39.24181938171387\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.1223822 | val_loss=0.0741839 val_MAE=0.2092065 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.07928252965211868, mae:0.22058717906475067\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:0.6059984024575813, mae:0.6098559774067923\n",
      "CSV saved → ./results/TEMPERATURE_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (17304, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --version Wavelets --root_path ./dataset/temperature/ --data_path temperature_dataset.csv --task_id TEMPERATURE_WITHLSTM_MS_Wavelets --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 24 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "725ac22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='GHI_WITHLSTM_MS_Wavelets', model='FEDformer', version='Wavelets', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/ghi/', data_path='ghi_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=24, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : GHI_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 40.40898299217224\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.4630751 | val_loss=0.2590999 val_MAE=0.3447623 |\n",
      "Validation loss decreased (inf --> 0.259100).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 39.1858229637146\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.2950350 | val_loss=0.2455230 val_MAE=0.3342047 |\n",
      "Validation loss decreased (0.259100 --> 0.245523).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 39.228551626205444\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.2690335 | val_loss=0.2260393 val_MAE=0.3076843 |\n",
      "Validation loss decreased (0.245523 --> 0.226039).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 39.96143889427185\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.2329101 | val_loss=0.2612983 val_MAE=0.3293731 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 39.734094858169556\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.2164137 | val_loss=0.2770647 val_MAE=0.3319435 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 40.27501821517944\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.2038933 | val_loss=0.2820778 val_MAE=0.3305269 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : GHI_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.3014000356197357, mae:0.34336453676223755\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:19882.65350178959, mae:88.1903333713682\n",
      "CSV saved → ./results/GHI_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : GHI_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 39.9766743183136\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.4916619 | val_loss=0.2352939 val_MAE=0.3318355 |\n",
      "Validation loss decreased (inf --> 0.235294).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 39.43329048156738\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.2965628 | val_loss=0.2976831 val_MAE=0.3662647 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 39.64017415046692\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.2554454 | val_loss=0.2888830 val_MAE=0.3455708 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 39.27916169166565\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.2292050 | val_loss=0.2847031 val_MAE=0.3377768 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : GHI_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.2999720573425293, mae:0.36294159293174744\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:19788.453160783214, mae:93.2185287678878\n",
      "CSV saved → ./results/GHI_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : GHI_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 39.372371196746826\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.4624505 | val_loss=0.2435045 val_MAE=0.3300204 |\n",
      "Validation loss decreased (inf --> 0.243504).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 39.96499943733215\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.2927427 | val_loss=0.2759517 val_MAE=0.3455651 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 39.51931309700012\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.2601136 | val_loss=0.3262987 val_MAE=0.3711709 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 39.89317202568054\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.2296981 | val_loss=0.2423509 val_MAE=0.3199888 |\n",
      "Validation loss decreased (0.243504 --> 0.242351).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 40.81036424636841\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.2080699 | val_loss=0.2797496 val_MAE=0.3318008 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 39.557164907455444\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.1953046 | val_loss=0.3013397 val_MAE=0.3403773 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 39.02302551269531\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.1873598 | val_loss=0.2766043 val_MAE=0.3285926 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : GHI_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.32296985387802124, mae:0.35120904445648193\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:21305.564044624374, mae:90.20513084716234\n",
      "CSV saved → ./results/GHI_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (17304, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --version Wavelets --root_path ./dataset/ghi/ --data_path ghi_dataset.csv --task_id GHI_WITHLSTM_MS_Wavelets --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 24 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcf3605f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='KW_WITHLSTM_MS_Wavelets', model='FEDformer', version='Wavelets', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/kw/', data_path='kw_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=24, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : KW_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 39.79281783103943\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (inf --> nan).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 38.75358867645264\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 39.44448781013489\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 38.99197483062744\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 39.2161705493927\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 39.1965696811676\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 38.98277425765991\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 8 cost time: 39.3411602973938\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 8, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 9 cost time: 39.288548946380615\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 9, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 10 cost time: 39.56342530250549\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 10, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : KW_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:nan, mae:nan\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:nan, mae:nan\n",
      "CSV saved → ./results/KW_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : KW_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 39.538007974624634\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.3392744 | val_loss=0.1733255 val_MAE=0.3265517 |\n",
      "Validation loss decreased (inf --> 0.173326).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 40.11100244522095\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.1719469 | val_loss=0.1735838 val_MAE=0.3204677 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 39.22517108917236\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.1424886 | val_loss=0.1758725 val_MAE=0.3207934 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 39.433122873306274\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.1247759 | val_loss=0.1444338 val_MAE=0.2960564 |\n",
      "Validation loss decreased (0.173326 --> 0.144434).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 39.77636694908142\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.1104602 | val_loss=0.1405537 val_MAE=0.2932529 |\n",
      "Validation loss decreased (0.144434 --> 0.140554).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 39.33901929855347\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.1033881 | val_loss=0.1376991 val_MAE=0.2877901 |\n",
      "Validation loss decreased (0.140554 --> 0.137699).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 39.95667576789856\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.0992836 | val_loss=0.1400043 val_MAE=0.2911388 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 8 cost time: 38.99834680557251\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 8, Steps 66 | train_loss=0.0968710 | val_loss=0.1406071 val_MAE=0.2928463 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 9 cost time: 39.32618284225464\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 9, Steps 66 | train_loss=0.0957186 | val_loss=0.1397006 val_MAE=0.2908317 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : KW_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.15055975317955017, mae:0.2882779836654663\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:2316.140209408131, mae:35.75522130103201\n",
      "CSV saved → ./results/KW_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : KW_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 39.367631673812866\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.4058036 | val_loss=0.1831659 val_MAE=0.3297760 |\n",
      "Validation loss decreased (inf --> 0.183166).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 39.195581674575806\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.1790718 | val_loss=0.1625777 val_MAE=0.3148804 |\n",
      "Validation loss decreased (0.183166 --> 0.162578).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 39.063263177871704\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.1512581 | val_loss=0.1606818 val_MAE=0.3126262 |\n",
      "Validation loss decreased (0.162578 --> 0.160682).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 39.32956004142761\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.1316162 | val_loss=0.1596428 val_MAE=0.3131288 |\n",
      "Validation loss decreased (0.160682 --> 0.159643).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 40.339699506759644\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.1222686 | val_loss=0.1540880 val_MAE=0.3065448 |\n",
      "Validation loss decreased (0.159643 --> 0.154088).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 39.80623435974121\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.1152281 | val_loss=0.1494599 val_MAE=0.3024292 |\n",
      "Validation loss decreased (0.154088 --> 0.149460).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 39.53853702545166\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.1126940 | val_loss=0.1429402 val_MAE=0.2941884 |\n",
      "Validation loss decreased (0.149460 --> 0.142940).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 8 cost time: 39.11236500740051\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 8, Steps 66 | train_loss=0.1105249 | val_loss=0.1451111 val_MAE=0.2965412 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 9 cost time: 39.41012096405029\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 9, Steps 66 | train_loss=0.1091628 | val_loss=0.1447598 val_MAE=0.2970122 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 10 cost time: 39.46147179603577\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 10, Steps 66 | train_loss=0.1091019 | val_loss=0.1440940 val_MAE=0.2959822 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : KW_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.15737132728099823, mae:0.3002321124076843\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:2420.9263867374, mae:37.23789667798381\n",
      "CSV saved → ./results/KW_WITHLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (17304, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --version Wavelets --root_path ./dataset/kw/ --data_path kw_dataset.csv --task_id KW_WITHLSTM_MS_Wavelets --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 24 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57c2fdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='KW_WITHLSTM_MS_Wavelets_tambahan', model='FEDformer', version='Wavelets', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/kw/', data_path='kw_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=24, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : KW_WITHLSTM_MS_Wavelets_tambahan_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 40.19150733947754\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.3597442 | val_loss=0.1769455 val_MAE=0.3311401 |\n",
      "Validation loss decreased (inf --> 0.176945).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 40.87785363197327\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.1767553 | val_loss=0.1737155 val_MAE=0.3277431 |\n",
      "Validation loss decreased (0.176945 --> 0.173716).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 39.4811897277832\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.1519204 | val_loss=0.1649258 val_MAE=0.3154862 |\n",
      "Validation loss decreased (0.173716 --> 0.164926).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 39.89015984535217\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.1320582 | val_loss=0.1553539 val_MAE=0.3050778 |\n",
      "Validation loss decreased (0.164926 --> 0.155354).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 40.289241552352905\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.1225267 | val_loss=0.1497826 val_MAE=0.3009447 |\n",
      "Validation loss decreased (0.155354 --> 0.149783).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 39.19968056678772\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.1150849 | val_loss=0.1418297 val_MAE=0.2922571 |\n",
      "Validation loss decreased (0.149783 --> 0.141830).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 40.16294288635254\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.1128072 | val_loss=0.1455302 val_MAE=0.2969297 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 8 cost time: 39.16309142112732\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 8, Steps 66 | train_loss=0.1106372 | val_loss=0.1415630 val_MAE=0.2918021 |\n",
      "Validation loss decreased (0.141830 --> 0.141563).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 9 cost time: 38.453612327575684\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 9, Steps 66 | train_loss=0.1094284 | val_loss=0.1419869 val_MAE=0.2922488 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 10 cost time: 38.69882559776306\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 10, Steps 66 | train_loss=0.1082672 | val_loss=0.1422752 val_MAE=0.2925619 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : KW_WITHLSTM_MS_Wavelets_tambahan_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.15462075173854828, mae:0.29482659697532654\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:2378.612780875382, mae:36.5674447856365\n",
      "CSV saved → ./results/KW_WITHLSTM_MS_Wavelets_tambahan_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (17304, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --version Wavelets --root_path ./dataset/kw/ --data_path kw_dataset.csv --task_id KW_WITHLSTM_MS_Wavelets_tambahan --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 24 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 1 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05fba271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='TEMPERATURE_WITHLSTM1hour_MS', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/temperature/', data_path='temperature_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=1, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=6, index_q=[0, 1, 2, 3, 4, 5]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : TEMPERATURE_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 33.0177206993103\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.1695446 | val_loss=0.0287600 val_MAE=0.1332085 |\n",
      "Validation loss decreased (inf --> 0.028760).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 30.08953070640564\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0347293 | val_loss=0.0321016 val_MAE=0.1516201 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 28.768946647644043\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0217545 | val_loss=0.0133336 val_MAE=0.0930867 |\n",
      "Validation loss decreased (0.028760 --> 0.013334).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 29.18176817893982\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0178359 | val_loss=0.0122985 val_MAE=0.0915002 |\n",
      "Validation loss decreased (0.013334 --> 0.012299).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 28.88950276374817\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0148655 | val_loss=0.0079344 val_MAE=0.0714881 |\n",
      "Validation loss decreased (0.012299 --> 0.007934).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 28.958669662475586\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0145949 | val_loss=0.0077420 val_MAE=0.0688515 |\n",
      "Validation loss decreased (0.007934 --> 0.007742).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 28.921831846237183\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.0129966 | val_loss=0.0082227 val_MAE=0.0708216 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 28.73465347290039\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.0125781 | val_loss=0.0076284 val_MAE=0.0683630 |\n",
      "Validation loss decreased (0.007742 --> 0.007628).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 29.46096658706665\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.0130007 | val_loss=0.0077229 val_MAE=0.0692134 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 10 cost time: 28.847312211990356\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 10, Steps 67 | train_loss=0.0126309 | val_loss=0.0078258 val_MAE=0.0690598 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.008902180939912796, mae:0.07252910733222961\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:0.06804409011706812, mae:0.2005207502746862\n",
      "CSV saved → ./results/TEMPERATURE_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=6, index_q=[0, 1, 2, 3, 4, 5]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : TEMPERATURE_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 31.096266269683838\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.1314345 | val_loss=0.0365207 val_MAE=0.1532673 |\n",
      "Validation loss decreased (inf --> 0.036521).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 31.44238042831421\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0360105 | val_loss=0.0278309 val_MAE=0.1391266 |\n",
      "Validation loss decreased (0.036521 --> 0.027831).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 31.297168254852295\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0195143 | val_loss=0.0150741 val_MAE=0.1045477 |\n",
      "Validation loss decreased (0.027831 --> 0.015074).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 31.85914182662964\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0145800 | val_loss=0.0095540 val_MAE=0.0796097 |\n",
      "Validation loss decreased (0.015074 --> 0.009554).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 31.497240781784058\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0132552 | val_loss=0.0079393 val_MAE=0.0706145 |\n",
      "Validation loss decreased (0.009554 --> 0.007939).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 31.510037422180176\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0122743 | val_loss=0.0085000 val_MAE=0.0757458 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 30.923654794692993\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.0115302 | val_loss=0.0066520 val_MAE=0.0653726 |\n",
      "Validation loss decreased (0.007939 --> 0.006652).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 31.298871994018555\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.0115638 | val_loss=0.0071152 val_MAE=0.0672783 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 31.18658137321472\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.0116573 | val_loss=0.0070744 val_MAE=0.0690021 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 10 cost time: 31.516623973846436\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 10, Steps 67 | train_loss=0.0109308 | val_loss=0.0071137 val_MAE=0.0689555 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.009423865005373955, mae:0.07773097604513168\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:0.07203159556253302, mae:0.21490232092316555\n",
      "CSV saved → ./results/TEMPERATURE_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=6, index_q=[0, 1, 2, 3, 4, 5]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : TEMPERATURE_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 31.148497819900513\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.1558632 | val_loss=0.0446680 val_MAE=0.1777619 |\n",
      "Validation loss decreased (inf --> 0.044668).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 30.804651021957397\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0332845 | val_loss=0.0417991 val_MAE=0.1857981 |\n",
      "Validation loss decreased (0.044668 --> 0.041799).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 30.903417825698853\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0212403 | val_loss=0.0215082 val_MAE=0.1262661 |\n",
      "Validation loss decreased (0.041799 --> 0.021508).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 31.393699884414673\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0156944 | val_loss=0.0066211 val_MAE=0.0632688 |\n",
      "Validation loss decreased (0.021508 --> 0.006621).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 30.863489866256714\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0123842 | val_loss=0.0053427 val_MAE=0.0563464 |\n",
      "Validation loss decreased (0.006621 --> 0.005343).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 31.76065993309021\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0129757 | val_loss=0.0068558 val_MAE=0.0658985 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 31.388607025146484\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.0122997 | val_loss=0.0071478 val_MAE=0.0666825 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 31.20967197418213\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.0122244 | val_loss=0.0080211 val_MAE=0.0722983 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.007438688073307276, mae:0.06589650362730026\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:0.056857837188426096, mae:0.1821836360282743\n",
      "CSV saved → ./results/TEMPERATURE_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (744, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --root_path ./dataset/temperature/ --data_path temperature_dataset.csv --task_id TEMPERATURE_WITHLSTM1hour_MS --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 1 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8a6a8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='GHI_WITHLSTM1hour_MS', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/ghi/', data_path='ghi_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=1, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=6, index_q=[0, 1, 2, 3, 4, 5]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : GHI_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 32.088536977767944\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.3075665 | val_loss=0.1659923 val_MAE=0.2737102 |\n",
      "Validation loss decreased (inf --> 0.165992).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 30.651519298553467\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.1740718 | val_loss=0.1669552 val_MAE=0.2858949 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 31.531113862991333\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.1491068 | val_loss=0.1518879 val_MAE=0.2369407 |\n",
      "Validation loss decreased (0.165992 --> 0.151888).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 30.62740206718445\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.1386133 | val_loss=0.1477852 val_MAE=0.2206877 |\n",
      "Validation loss decreased (0.151888 --> 0.147785).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 30.649206399917603\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.1304654 | val_loss=0.1430675 val_MAE=0.2223742 |\n",
      "Validation loss decreased (0.147785 --> 0.143067).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 30.181769609451294\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.1275944 | val_loss=0.1403786 val_MAE=0.2143463 |\n",
      "Validation loss decreased (0.143067 --> 0.140379).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 30.704389333724976\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.1266045 | val_loss=0.1429156 val_MAE=0.2274388 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 30.963881015777588\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.1252266 | val_loss=0.1409714 val_MAE=0.2209913 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 31.31045150756836\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.1251741 | val_loss=0.1407422 val_MAE=0.2193588 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : GHI_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.14520922303199768, mae:0.2154298573732376\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:9579.111815070004, mae:55.33136644830278\n",
      "CSV saved → ./results/GHI_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=6, index_q=[0, 1, 2, 3, 4, 5]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : GHI_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 31.013296365737915\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.2773936 | val_loss=0.1842306 val_MAE=0.2746069 |\n",
      "Validation loss decreased (inf --> 0.184231).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 30.612729787826538\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.1601053 | val_loss=0.1712830 val_MAE=0.2730531 |\n",
      "Validation loss decreased (0.184231 --> 0.171283).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 30.15992045402527\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.1421746 | val_loss=0.1560642 val_MAE=0.2499097 |\n",
      "Validation loss decreased (0.171283 --> 0.156064).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 31.453694343566895\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.1348700 | val_loss=0.1540193 val_MAE=0.2543261 |\n",
      "Validation loss decreased (0.156064 --> 0.154019).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 31.159836769104004\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.1306472 | val_loss=0.1441783 val_MAE=0.2302712 |\n",
      "Validation loss decreased (0.154019 --> 0.144178).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 31.41275453567505\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.1261774 | val_loss=0.1419467 val_MAE=0.2182729 |\n",
      "Validation loss decreased (0.144178 --> 0.141947).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 30.923407793045044\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.1229726 | val_loss=0.1414589 val_MAE=0.2188288 |\n",
      "Validation loss decreased (0.141947 --> 0.141459).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 31.08290696144104\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.1249821 | val_loss=0.1407073 val_MAE=0.2144427 |\n",
      "Validation loss decreased (0.141459 --> 0.140707).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 31.011837482452393\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.1265059 | val_loss=0.1414843 val_MAE=0.2188065 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 10 cost time: 30.12378478050232\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 10, Steps 67 | train_loss=0.1237465 | val_loss=0.1413383 val_MAE=0.2179713 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : GHI_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.14361293613910675, mae:0.209981769323349\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:9473.809241537769, mae:53.9320769085627\n",
      "CSV saved → ./results/GHI_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=6, index_q=[0, 1, 2, 3, 4, 5]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : GHI_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 43.73282170295715\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.3386746 | val_loss=0.1621173 val_MAE=0.2726443 |\n",
      "Validation loss decreased (inf --> 0.162117).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 29.115408658981323\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.1608135 | val_loss=0.1572047 val_MAE=0.2644390 |\n",
      "Validation loss decreased (0.162117 --> 0.157205).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 29.287831783294678\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.1599456 | val_loss=0.1667747 val_MAE=0.2566877 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 29.80253553390503\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.1405669 | val_loss=0.1390198 val_MAE=0.2281748 |\n",
      "Validation loss decreased (0.157205 --> 0.139020).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 31.537389516830444\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.1294517 | val_loss=0.1404955 val_MAE=0.2244501 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 31.4147469997406\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.1296430 | val_loss=0.1380020 val_MAE=0.2156044 |\n",
      "Validation loss decreased (0.139020 --> 0.138002).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 31.787734270095825\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.1274334 | val_loss=0.1418657 val_MAE=0.2228911 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 31.41570281982422\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.1265476 | val_loss=0.1400882 val_MAE=0.2199590 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 31.181938886642456\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.1265989 | val_loss=0.1402097 val_MAE=0.2192131 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : GHI_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.14642678201198578, mae:0.2142409086227417\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:9659.432138711078, mae:55.02599791204619\n",
      "CSV saved → ./results/GHI_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (744, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --root_path ./dataset/ghi/ --data_path ghi_dataset.csv --task_id GHI_WITHLSTM1hour_MS --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 1 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd9d6b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='KW_WITHLSTM1hour_MS', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/kw/', data_path='kw_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=1, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=6, index_q=[0, 1, 2, 3, 4, 5]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : KW_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 31.9460289478302\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.2685478 | val_loss=0.1342779 val_MAE=0.2918618 |\n",
      "Validation loss decreased (inf --> 0.134278).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 30.959415197372437\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0676136 | val_loss=0.0751945 val_MAE=0.2181148 |\n",
      "Validation loss decreased (0.134278 --> 0.075194).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 30.66944932937622\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0529520 | val_loss=0.0455587 val_MAE=0.1642423 |\n",
      "Validation loss decreased (0.075194 --> 0.045559).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 31.05646014213562\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0464207 | val_loss=0.0497758 val_MAE=0.1699419 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 30.741928815841675\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0458883 | val_loss=0.0491785 val_MAE=0.1741143 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 30.57395887374878\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0431771 | val_loss=0.0428063 val_MAE=0.1604541 |\n",
      "Validation loss decreased (0.045559 --> 0.042806).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 30.650485277175903\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.0421096 | val_loss=0.0441917 val_MAE=0.1627451 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 30.924476146697998\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.0417380 | val_loss=0.0463614 val_MAE=0.1682403 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 30.60240077972412\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.0408380 | val_loss=0.0445929 val_MAE=0.1638429 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : KW_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.04700500890612602, mae:0.1610441654920578\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:723.1029017029177, mae:19.97436598121029\n",
      "CSV saved → ./results/KW_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=6, index_q=[0, 1, 2, 3, 4, 5]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : KW_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 31.13132119178772\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.1751201 | val_loss=0.0852483 val_MAE=0.2299944 |\n",
      "Validation loss decreased (inf --> 0.085248).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 30.914608240127563\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0642192 | val_loss=0.0545546 val_MAE=0.1854204 |\n",
      "Validation loss decreased (0.085248 --> 0.054555).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 30.8864266872406\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0499564 | val_loss=0.0697942 val_MAE=0.2072636 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 30.970454931259155\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0471499 | val_loss=0.0492149 val_MAE=0.1740930 |\n",
      "Validation loss decreased (0.054555 --> 0.049215).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 31.191063404083252\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0419321 | val_loss=0.0529483 val_MAE=0.1804798 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 30.963321447372437\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0389385 | val_loss=0.0454418 val_MAE=0.1656497 |\n",
      "Validation loss decreased (0.049215 --> 0.045442).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 31.098265171051025\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.0385925 | val_loss=0.0445026 val_MAE=0.1632829 |\n",
      "Validation loss decreased (0.045442 --> 0.044503).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 31.08932137489319\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.0390177 | val_loss=0.0436747 val_MAE=0.1616705 |\n",
      "Validation loss decreased (0.044503 --> 0.043675).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 30.68042302131653\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.0383724 | val_loss=0.0453418 val_MAE=0.1649906 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 10 cost time: 30.608306646347046\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 10, Steps 67 | train_loss=0.0382188 | val_loss=0.0440907 val_MAE=0.1620779 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : KW_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.047892969101667404, mae:0.1657094955444336\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:736.7628505758563, mae:20.55300696560839\n",
      "CSV saved → ./results/KW_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=6, index_q=[0, 1, 2, 3, 4, 5]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : KW_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 30.916004419326782\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.2385422 | val_loss=0.0595274 val_MAE=0.1896905 |\n",
      "Validation loss decreased (inf --> 0.059527).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 31.692293167114258\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0644360 | val_loss=0.1255952 val_MAE=0.2809956 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 30.85803484916687\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0503257 | val_loss=0.0509861 val_MAE=0.1754311 |\n",
      "Validation loss decreased (0.059527 --> 0.050986).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 30.759695053100586\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0429580 | val_loss=0.0473066 val_MAE=0.1695478 |\n",
      "Validation loss decreased (0.050986 --> 0.047307).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 30.928688287734985\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0404742 | val_loss=0.0487096 val_MAE=0.1724319 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 30.9931640625\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0392513 | val_loss=0.0414388 val_MAE=0.1576711 |\n",
      "Validation loss decreased (0.047307 --> 0.041439).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 31.09252119064331\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.0385247 | val_loss=0.0422116 val_MAE=0.1580691 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 31.284368991851807\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.0394190 | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (0.041439 --> nan).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 30.681100368499756\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.0378205 | val_loss=0.0429258 val_MAE=0.1597847 |\n",
      "Validation loss decreased (nan --> 0.042926).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 10 cost time: 30.656514406204224\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 10, Steps 67 | train_loss=0.0391798 | val_loss=0.0432306 val_MAE=0.1602632 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : KW_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.04628298431634903, mae:0.16018597781658173\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:711.9956512405251, mae:19.86792394947964\n",
      "CSV saved → ./results/KW_WITHLSTM1hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (744, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --root_path ./dataset/kw/ --data_path kw_dataset.csv --task_id KW_WITHLSTM1hour_MS --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 1 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cef5fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='TEMPERATURE_WITHLSTM1hour_MS_wavelets', model='FEDformer', version='Wavelets', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/temperature/', data_path='temperature_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=1, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : TEMPERATURE_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 36.82442307472229\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.1703834 | val_loss=0.0214727 val_MAE=0.1230790 |\n",
      "Validation loss decreased (inf --> 0.021473).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 35.42338275909424\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0283231 | val_loss=0.0079970 val_MAE=0.0694921 |\n",
      "Validation loss decreased (0.021473 --> 0.007997).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 37.043330907821655\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0147796 | val_loss=0.0101830 val_MAE=0.0816880 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 35.98409914970398\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0116018 | val_loss=0.0047874 val_MAE=0.0542816 |\n",
      "Validation loss decreased (0.007997 --> 0.004787).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 36.01136779785156\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0100806 | val_loss=0.0043471 val_MAE=0.0519906 |\n",
      "Validation loss decreased (0.004787 --> 0.004347).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 36.446101665496826\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0092859 | val_loss=0.0036867 val_MAE=0.0473886 |\n",
      "Validation loss decreased (0.004347 --> 0.003687).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 36.10257267951965\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.0085130 | val_loss=0.0041519 val_MAE=0.0513348 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 36.8177969455719\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.0085194 | val_loss=0.0039121 val_MAE=0.0496842 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 36.43140983581543\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.0089091 | val_loss=0.0038411 val_MAE=0.0490563 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.004851016215980053, mae:0.05267719551920891\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:0.03707888495600842, mae:0.1456362904175901\n",
      "CSV saved → ./results/TEMPERATURE_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : TEMPERATURE_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 36.63898158073425\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.2269444 | val_loss=0.0331212 val_MAE=0.1479191 |\n",
      "Validation loss decreased (inf --> 0.033121).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 36.259952545166016\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0332301 | val_loss=0.0130050 val_MAE=0.0896046 |\n",
      "Validation loss decreased (0.033121 --> 0.013005).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 36.124857902526855\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0178998 | val_loss=0.0056600 val_MAE=0.0610097 |\n",
      "Validation loss decreased (0.013005 --> 0.005660).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 36.90736269950867\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0121861 | val_loss=0.0051249 val_MAE=0.0557074 |\n",
      "Validation loss decreased (0.005660 --> 0.005125).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 36.14085292816162\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0112041 | val_loss=0.0055243 val_MAE=0.0591807 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 36.061129570007324\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0097740 | val_loss=0.0059026 val_MAE=0.0593677 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 36.16315793991089\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.0098304 | val_loss=0.0040061 val_MAE=0.0487789 |\n",
      "Validation loss decreased (0.005125 --> 0.004006).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 36.434821128845215\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.0097633 | val_loss=0.0041804 val_MAE=0.0505028 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 36.0222110748291\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.0095363 | val_loss=0.0041509 val_MAE=0.0501567 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 10 cost time: 36.584078788757324\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 10, Steps 67 | train_loss=0.0093197 | val_loss=0.0041927 val_MAE=0.0500019 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.00449814647436142, mae:0.05065042898058891\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:0.034381718383467284, mae:0.1400328987431567\n",
      "CSV saved → ./results/TEMPERATURE_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : TEMPERATURE_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 35.97689700126648\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.2806487 | val_loss=0.0475267 val_MAE=0.1704592 |\n",
      "Validation loss decreased (inf --> 0.047527).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 36.32596826553345\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0339550 | val_loss=0.0227794 val_MAE=0.1236994 |\n",
      "Validation loss decreased (0.047527 --> 0.022779).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 36.023667335510254\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0187462 | val_loss=0.0101343 val_MAE=0.0780032 |\n",
      "Validation loss decreased (0.022779 --> 0.010134).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 36.54259014129639\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0134843 | val_loss=0.0059218 val_MAE=0.0606439 |\n",
      "Validation loss decreased (0.010134 --> 0.005922).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 35.891029357910156\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0106676 | val_loss=0.0057300 val_MAE=0.0593067 |\n",
      "Validation loss decreased (0.005922 --> 0.005730).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 35.875316858291626\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0098060 | val_loss=0.0046005 val_MAE=0.0526438 |\n",
      "Validation loss decreased (0.005730 --> 0.004600).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 36.12148571014404\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.0098774 | val_loss=0.0049591 val_MAE=0.0555227 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 36.19761538505554\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.0094882 | val_loss=0.0046072 val_MAE=0.0531021 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 35.92621040344238\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.0096896 | val_loss=0.0047780 val_MAE=0.0541758 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.004457701463252306, mae:0.05062795430421829\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:0.03407257198507949, mae:0.13997077001804786\n",
      "CSV saved → ./results/TEMPERATURE_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (744, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --version Wavelets --root_path ./dataset/temperature/ --data_path temperature_dataset.csv --task_id TEMPERATURE_WITHLSTM1hour_MS_wavelets --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 1 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a562432b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='GHI_WITHLSTM1hour_MS_wavelets', model='FEDformer', version='Wavelets', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/ghi/', data_path='ghi_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=1, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : GHI_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 36.682124853134155\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.3282329 | val_loss=0.1973668 val_MAE=0.3148613 |\n",
      "Validation loss decreased (inf --> 0.197367).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 36.18230652809143\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.1710608 | val_loss=0.1849725 val_MAE=0.2774905 |\n",
      "Validation loss decreased (0.197367 --> 0.184972).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 36.37379765510559\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.1402113 | val_loss=0.1502791 val_MAE=0.2192797 |\n",
      "Validation loss decreased (0.184972 --> 0.150279).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 36.425867319107056\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.1314407 | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (0.150279 --> nan).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 37.26188826560974\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.1271142 | val_loss=0.1487107 val_MAE=0.2223552 |\n",
      "Validation loss decreased (nan --> 0.148711).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 37.77112436294556\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.1181014 | val_loss=0.1456910 val_MAE=0.2185676 |\n",
      "Validation loss decreased (0.148711 --> 0.145691).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 36.570181131362915\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.1154049 | val_loss=0.1466137 val_MAE=0.2187529 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 36.86865711212158\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.1151150 | val_loss=0.1459964 val_MAE=0.2159083 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 36.76812767982483\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.1143403 | val_loss=0.1459418 val_MAE=0.2161971 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : GHI_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.14487087726593018, mae:0.2115163654088974\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:9556.792556865215, mae:54.3262253839455\n",
      "CSV saved → ./results/GHI_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : GHI_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 37.40203523635864\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.3349593 | val_loss=0.1613424 val_MAE=0.2384835 |\n",
      "Validation loss decreased (inf --> 0.161342).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 36.70230746269226\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.1693531 | val_loss=0.1726767 val_MAE=0.2854144 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 36.570964336395264\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.1443538 | val_loss=0.1982851 val_MAE=0.2917716 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 36.42228293418884\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.1352935 | val_loss=0.1455484 val_MAE=0.2273444 |\n",
      "Validation loss decreased (0.161342 --> 0.145548).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 36.39678430557251\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.1229471 | val_loss=0.1478850 val_MAE=0.2101878 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 37.29633116722107\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.1181761 | val_loss=0.1447272 val_MAE=0.2185046 |\n",
      "Validation loss decreased (0.145548 --> 0.144727).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 36.39438581466675\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.1155541 | val_loss=0.1436593 val_MAE=0.2122291 |\n",
      "Validation loss decreased (0.144727 --> 0.143659).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 36.38469696044922\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.1126091 | val_loss=0.1442429 val_MAE=0.2151215 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 36.38280534744263\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.1135774 | val_loss=0.1437318 val_MAE=0.2131475 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 10 cost time: 36.71259808540344\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 10, Steps 67 | train_loss=0.1148325 | val_loss=0.1437604 val_MAE=0.2131236 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : GHI_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.14426755905151367, mae:0.20432788133621216\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:9516.99261800322, mae:52.47991681401109\n",
      "CSV saved → ./results/GHI_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : GHI_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 37.46679091453552\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.3689595 | val_loss=0.1692265 val_MAE=0.2512246 |\n",
      "Validation loss decreased (inf --> 0.169227).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 36.57801556587219\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.1619650 | val_loss=0.1696918 val_MAE=0.2910219 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 36.61548662185669\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.1399576 | val_loss=0.1544236 val_MAE=0.2513796 |\n",
      "Validation loss decreased (0.169227 --> 0.154424).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 36.74116253852844\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.1309369 | val_loss=0.1483058 val_MAE=0.2235650 |\n",
      "Validation loss decreased (0.154424 --> 0.148306).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 36.943222522735596\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.1257017 | val_loss=0.1451598 val_MAE=0.2171036 |\n",
      "Validation loss decreased (0.148306 --> 0.145160).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 37.53369736671448\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.1194495 | val_loss=0.1438517 val_MAE=0.2110650 |\n",
      "Validation loss decreased (0.145160 --> 0.143852).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 36.65972018241882\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.1164634 | val_loss=0.1436580 val_MAE=0.2123442 |\n",
      "Validation loss decreased (0.143852 --> 0.143658).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 36.21461510658264\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.1171888 | val_loss=0.1429536 val_MAE=0.2093334 |\n",
      "Validation loss decreased (0.143658 --> 0.142954).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 36.455427169799805\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.1155648 | val_loss=0.1432753 val_MAE=0.2107742 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 10 cost time: 36.599459171295166\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 10, Steps 67 | train_loss=0.1137969 | val_loss=0.1432770 val_MAE=0.2109264 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : GHI_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.14261601865291595, mae:0.20263318717479706\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:9408.04449467835, mae:52.044653937884036\n",
      "CSV saved → ./results/GHI_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (744, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --version Wavelets --root_path ./dataset/ghi/ --data_path ghi_dataset.csv --task_id GHI_WITHLSTM1hour_MS_wavelets --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 1 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07f10312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='KW_WITHLSTM1hour_MS_wavelets', model='FEDformer', version='Wavelets', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/kw/', data_path='kw_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=1, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : KW_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 37.34257483482361\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.2643809 | val_loss=0.0862094 val_MAE=0.2344012 |\n",
      "Validation loss decreased (inf --> 0.086209).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 37.46672034263611\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0599546 | val_loss=0.0488082 val_MAE=0.1679009 |\n",
      "Validation loss decreased (0.086209 --> 0.048808).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 36.68005108833313\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0470579 | val_loss=0.0433667 val_MAE=0.1601581 |\n",
      "Validation loss decreased (0.048808 --> 0.043367).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 36.908451080322266\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0406729 | val_loss=0.0429268 val_MAE=0.1584149 |\n",
      "Validation loss decreased (0.043367 --> 0.042927).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 36.85733342170715\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0391880 | val_loss=0.0374562 val_MAE=0.1481182 |\n",
      "Validation loss decreased (0.042927 --> 0.037456).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 37.61060309410095\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0366209 | val_loss=0.0409753 val_MAE=0.1556374 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 36.64513945579529\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.0359435 | val_loss=0.0370540 val_MAE=0.1466565 |\n",
      "Validation loss decreased (0.037456 --> 0.037054).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 36.68498086929321\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.0358276 | val_loss=0.0394675 val_MAE=0.1517161 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 36.74048590660095\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.0355001 | val_loss=0.0392663 val_MAE=0.1512451 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 10 cost time: 36.77430033683777\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 10, Steps 67 | train_loss=0.0347135 | val_loss=0.0389863 val_MAE=0.1506857 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : KW_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.0391697958111763, mae:0.14620374143123627\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:602.569699316654, mae:18.133702512803026\n",
      "CSV saved → ./results/KW_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : KW_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 36.970398902893066\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.3306741 | val_loss=0.0847275 val_MAE=0.2334276 |\n",
      "Validation loss decreased (inf --> 0.084728).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 36.406676054000854\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0669061 | val_loss=0.0485829 val_MAE=0.1752603 |\n",
      "Validation loss decreased (0.084728 --> 0.048583).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 36.29375743865967\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0468029 | val_loss=0.0560433 val_MAE=0.1866226 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 36.523120641708374\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0418228 | val_loss=0.0386916 val_MAE=0.1530187 |\n",
      "Validation loss decreased (0.048583 --> 0.038692).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 36.281309366226196\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0384168 | val_loss=0.0384148 val_MAE=0.1521813 |\n",
      "Validation loss decreased (0.038692 --> 0.038415).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 36.783477783203125\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0370562 | val_loss=0.0367984 val_MAE=0.1477179 |\n",
      "Validation loss decreased (0.038415 --> 0.036798).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 36.29867196083069\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.0364794 | val_loss=0.0387366 val_MAE=0.1517851 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 36.65364599227905\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.0358875 | val_loss=0.0368085 val_MAE=0.1474502 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 38.43990087509155\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.0371065 | val_loss=0.0379151 val_MAE=0.1497367 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : KW_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.03768007457256317, mae:0.14505818486213684\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:579.652478801443, mae:17.991617532380527\n",
      "CSV saved → ./results/KW_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : KW_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 36.14468216896057\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.4012444 | val_loss=0.1171965 val_MAE=0.2760150 |\n",
      "Validation loss decreased (inf --> 0.117196).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 36.87599754333496\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0627070 | val_loss=0.0898401 val_MAE=0.2419734 |\n",
      "Validation loss decreased (0.117196 --> 0.089840).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 37.108750343322754\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0543174 | val_loss=0.0516549 val_MAE=0.1809087 |\n",
      "Validation loss decreased (0.089840 --> 0.051655).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 36.833542346954346\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0429750 | val_loss=0.0506807 val_MAE=0.1750018 |\n",
      "Validation loss decreased (0.051655 --> 0.050681).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 36.88363742828369\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0397903 | val_loss=0.0388672 val_MAE=0.1527380 |\n",
      "Validation loss decreased (0.050681 --> 0.038867).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 36.76072120666504\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0384914 | val_loss=0.0430417 val_MAE=0.1605266 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 36.84928107261658\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.0375029 | val_loss=0.0421643 val_MAE=0.1586248 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 36.399686336517334\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.0372131 | val_loss=0.0406873 val_MAE=0.1551838 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : KW_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.04268674552440643, mae:0.15694384276866913\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:656.6727808213502, mae:19.46580044843279\n",
      "CSV saved → ./results/KW_WITHLSTM1hour_MS_wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (744, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --version Wavelets --root_path ./dataset/kw/ --data_path kw_dataset.csv --task_id KW_WITHLSTM1hour_MS_wavelets --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 1 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
