{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be3c273b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='TEMPERATURE_WITHOUTLSTM_MS', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/temperature/', data_path='temperature_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=24, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=18, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : TEMPERATURE_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 31.88967728614807\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.3097294 | val_loss=0.0568319 val_MAE=0.1870241 |\n",
      "Validation loss decreased (inf --> 0.056832).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 29.3233745098114\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.2547299 | val_loss=0.0484791 val_MAE=0.1724394 |\n",
      "Validation loss decreased (0.056832 --> 0.048479).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 30.318612575531006\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.2312728 | val_loss=0.0534188 val_MAE=0.1823418 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 31.814714908599854\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.2175931 | val_loss=0.0492983 val_MAE=0.1749647 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 31.17013430595398\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (0.048479 --> nan).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 31.617827892303467\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 31.592808485031128\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 8 cost time: 31.519291877746582\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 8, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 9 cost time: 31.565333604812622\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 9, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 10 cost time: 31.822301864624023\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 10, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:nan, mae:nan\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:nan, mae:nan\n",
      "CSV saved → ./results/TEMPERATURE_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=18, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : TEMPERATURE_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 31.12475085258484\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.3066446 | val_loss=0.0619771 val_MAE=0.1923070 |\n",
      "Validation loss decreased (inf --> 0.061977).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 31.331860303878784\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.2543672 | val_loss=0.0519845 val_MAE=0.1798431 |\n",
      "Validation loss decreased (0.061977 --> 0.051985).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 31.586247444152832\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.2297175 | val_loss=0.0506614 val_MAE=0.1788938 |\n",
      "Validation loss decreased (0.051985 --> 0.050661).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 31.288382530212402\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.2145880 | val_loss=0.0483085 val_MAE=0.1733848 |\n",
      "Validation loss decreased (0.050661 --> 0.048309).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 31.989186763763428\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.2049231 | val_loss=0.0529586 val_MAE=0.1801228 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 31.12611722946167\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.1997682 | val_loss=0.0484819 val_MAE=0.1724442 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 30.95459532737732\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.1996548 | val_loss=0.0471676 val_MAE=0.1707942 |\n",
      "Validation loss decreased (0.048309 --> 0.047168).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 8 cost time: 31.28434419631958\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 8, Steps 66 | train_loss=0.1977133 | val_loss=0.0479191 val_MAE=0.1715150 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 9 cost time: 31.64606523513794\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 9, Steps 66 | train_loss=0.1972946 | val_loss=0.0480851 val_MAE=0.1720305 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 10 cost time: 31.35815715789795\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 10, Steps 66 | train_loss=0.1967977 | val_loss=0.0480193 val_MAE=0.1719248 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.07304893434047699, mae:0.20676788687705994\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:0.5583517399005379, mae:0.5716498567012884\n",
      "CSV saved → ./results/TEMPERATURE_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=18, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : TEMPERATURE_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 31.839807510375977\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.2993688 | val_loss=0.0503503 val_MAE=0.1805687 |\n",
      "Validation loss decreased (inf --> 0.050350).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 31.511263608932495\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.2507179 | val_loss=0.0501608 val_MAE=0.1765778 |\n",
      "Validation loss decreased (0.050350 --> 0.050161).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 31.534163236618042\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.2252167 | val_loss=0.0476893 val_MAE=0.1721338 |\n",
      "Validation loss decreased (0.050161 --> 0.047689).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 31.601646661758423\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.2067208 | val_loss=0.0527700 val_MAE=0.1798421 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 31.243337869644165\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.1989573 | val_loss=0.0471079 val_MAE=0.1725260 |\n",
      "Validation loss decreased (0.047689 --> 0.047108).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 31.36024045944214\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.1966891 | val_loss=0.0475346 val_MAE=0.1720680 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 31.7706196308136\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.1943112 | val_loss=0.0478085 val_MAE=0.1722210 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 8 cost time: 31.683746099472046\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 8, Steps 66 | train_loss=0.1950975 | val_loss=0.0481077 val_MAE=0.1729590 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.07143338024616241, mae:0.20703372359275818\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:0.546003193501707, mae:0.5723847698636327\n",
      "CSV saved → ./results/TEMPERATURE_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (17304, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --root_path ./dataset/temperature/ --data_path temperature_dataset.csv --task_id TEMPERATURE_WITHOUTLSTM_MS --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 24 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98cd2dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='GHI_WITHOUTLSTM_MS', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/ghi/', data_path='ghi_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=24, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=18, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : GHI_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 32.41430163383484\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.4865908 | val_loss=0.3148245 val_MAE=0.4123541 |\n",
      "Validation loss decreased (inf --> 0.314825).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 31.629520893096924\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.3899498 | val_loss=0.3060586 val_MAE=0.3979998 |\n",
      "Validation loss decreased (0.314825 --> 0.306059).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 31.481877326965332\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.3549500 | val_loss=0.2876276 val_MAE=0.3786413 |\n",
      "Validation loss decreased (0.306059 --> 0.287628).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 31.954659461975098\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.3432219 | val_loss=0.2546244 val_MAE=0.3474078 |\n",
      "Validation loss decreased (0.287628 --> 0.254624).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 29.57707691192627\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.3366775 | val_loss=0.2721417 val_MAE=0.3600363 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 30.172160148620605\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.3334678 | val_loss=0.2592843 val_MAE=0.3479233 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 29.788007259368896\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.3329251 | val_loss=0.2632563 val_MAE=0.3512954 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : GHI_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.3289133906364441, mae:0.39153429865837097\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:21697.643691948648, mae:100.5623262066763\n",
      "CSV saved → ./results/GHI_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=18, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : GHI_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 30.11084485054016\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.5078160 | val_loss=0.3439505 val_MAE=0.4514437 |\n",
      "Validation loss decreased (inf --> 0.343951).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 29.621657848358154\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.3830725 | val_loss=0.2747137 val_MAE=0.3735130 |\n",
      "Validation loss decreased (0.343951 --> 0.274714).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 29.910987854003906\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.3552539 | val_loss=0.2556472 val_MAE=0.3554839 |\n",
      "Validation loss decreased (0.274714 --> 0.255647).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 29.605161905288696\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.3440134 | val_loss=0.2622343 val_MAE=0.3553453 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 29.46828031539917\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.3391848 | val_loss=0.2757980 val_MAE=0.3645927 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 29.689131021499634\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.3349934 | val_loss=0.2662105 val_MAE=0.3577234 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : GHI_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.33294492959976196, mae:0.39721235632896423\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:21963.597780763455, mae:102.0206982301207\n",
      "CSV saved → ./results/GHI_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=18, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : GHI_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 30.148563861846924\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.5035605 | val_loss=0.3097467 val_MAE=0.4073311 |\n",
      "Validation loss decreased (inf --> 0.309747).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 29.444722414016724\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.3823676 | val_loss=0.2675668 val_MAE=0.3667271 |\n",
      "Validation loss decreased (0.309747 --> 0.267567).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 29.988038301467896\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.3572785 | val_loss=0.2700088 val_MAE=0.3653434 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 29.441672563552856\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.3440192 | val_loss=0.2587433 val_MAE=0.3527817 |\n",
      "Validation loss decreased (0.267567 --> 0.258743).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 29.521368741989136\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.3394432 | val_loss=0.2660738 val_MAE=0.3560142 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 29.39037322998047\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.3366409 | val_loss=0.2602584 val_MAE=0.3524454 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 29.82730269432068\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.3350154 | val_loss=0.2618365 val_MAE=0.3519919 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : GHI_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.3302169144153595, mae:0.3950023055076599\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:21783.635804609246, mae:101.45307219409774\n",
      "CSV saved → ./results/GHI_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (17304, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --root_path ./dataset/ghi/ --data_path ghi_dataset.csv --task_id GHI_WITHOUTLSTM_MS --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 24 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2a3f8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='KW_WITHOUTLSTM_MS', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/kw/', data_path='kw_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=24, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=18, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : KW_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 31.030102014541626\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.3577120 | val_loss=0.2239264 val_MAE=0.3682870 |\n",
      "Validation loss decreased (inf --> 0.223926).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 29.289407968521118\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.2465454 | val_loss=0.1947351 val_MAE=0.3405603 |\n",
      "Validation loss decreased (0.223926 --> 0.194735).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 29.324636220932007\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.2067742 | val_loss=0.1729149 val_MAE=0.3190131 |\n",
      "Validation loss decreased (0.194735 --> 0.172915).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 29.501513481140137\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.1947788 | val_loss=0.1676258 val_MAE=0.3129632 |\n",
      "Validation loss decreased (0.172915 --> 0.167626).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 29.479240894317627\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.1884565 | val_loss=0.1651924 val_MAE=0.3110821 |\n",
      "Validation loss decreased (0.167626 --> 0.165192).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 29.49837374687195\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.1843616 | val_loss=0.1643107 val_MAE=0.3105883 |\n",
      "Validation loss decreased (0.165192 --> 0.164311).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 29.266757488250732\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.1831450 | val_loss=0.1640220 val_MAE=0.3102301 |\n",
      "Validation loss decreased (0.164311 --> 0.164022).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 8 cost time: 29.65031909942627\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 8, Steps 66 | train_loss=0.1826387 | val_loss=0.1635478 val_MAE=0.3095715 |\n",
      "Validation loss decreased (0.164022 --> 0.163548).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 9 cost time: 29.28988742828369\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 9, Steps 66 | train_loss=0.1820826 | val_loss=0.1636078 val_MAE=0.3096816 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 10 cost time: 29.84332275390625\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 10, Steps 66 | train_loss=0.1815506 | val_loss=0.1635796 val_MAE=0.3096944 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : KW_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.18009455502033234, mae:0.31666189432144165\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:2770.489800868054, mae:39.275687132931914\n",
      "CSV saved → ./results/KW_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=18, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : KW_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 29.379616022109985\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.3415193 | val_loss=0.2216346 val_MAE=0.3634956 |\n",
      "Validation loss decreased (inf --> 0.221635).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 29.92850923538208\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.2394423 | val_loss=0.1761511 val_MAE=0.3227789 |\n",
      "Validation loss decreased (0.221635 --> 0.176151).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 29.349241256713867\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.2053026 | val_loss=0.1704548 val_MAE=0.3150537 |\n",
      "Validation loss decreased (0.176151 --> 0.170455).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 29.52808666229248\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.1934050 | val_loss=0.1732113 val_MAE=0.3200460 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 29.323201656341553\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.1859122 | val_loss=0.1678881 val_MAE=0.3130338 |\n",
      "Validation loss decreased (0.170455 --> 0.167888).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 29.478319883346558\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.1835306 | val_loss=0.1669992 val_MAE=0.3132364 |\n",
      "Validation loss decreased (0.167888 --> 0.166999).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 29.426474571228027\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.1833196 | val_loss=0.1665847 val_MAE=0.3119729 |\n",
      "Validation loss decreased (0.166999 --> 0.166585).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 8 cost time: 30.221463918685913\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 8, Steps 66 | train_loss=0.1817235 | val_loss=0.1663987 val_MAE=0.3120320 |\n",
      "Validation loss decreased (0.166585 --> 0.166399).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 9 cost time: 29.25986647605896\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 9, Steps 66 | train_loss=0.1804052 | val_loss=0.1667656 val_MAE=0.3127849 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 10 cost time: 30.12862801551819\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 10, Steps 66 | train_loss=0.1816246 | val_loss=0.1666212 val_MAE=0.3125655 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : KW_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.18644405901432037, mae:0.32136309146881104\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:2868.167440996899, mae:39.85877733577432\n",
      "CSV saved → ./results/KW_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=18, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : KW_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 29.543769598007202\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.3903685 | val_loss=0.2214271 val_MAE=0.3669679 |\n",
      "Validation loss decreased (inf --> 0.221427).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 29.51052951812744\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.2566553 | val_loss=0.1905578 val_MAE=0.3362006 |\n",
      "Validation loss decreased (0.221427 --> 0.190558).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 29.466965436935425\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.2139217 | val_loss=0.1748750 val_MAE=0.3212682 |\n",
      "Validation loss decreased (0.190558 --> 0.174875).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 29.398269176483154\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.2023551 | val_loss=0.1759255 val_MAE=0.3224515 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 29.239257097244263\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.1951658 | val_loss=0.1706009 val_MAE=0.3173073 |\n",
      "Validation loss decreased (0.174875 --> 0.170601).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 30.05663275718689\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.1927172 | val_loss=0.1678159 val_MAE=0.3134422 |\n",
      "Validation loss decreased (0.170601 --> 0.167816).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 29.361786365509033\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.1916031 | val_loss=0.1679321 val_MAE=0.3142354 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 8 cost time: 29.578808069229126\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 8, Steps 66 | train_loss=0.1909836 | val_loss=0.1670162 val_MAE=0.3130926 |\n",
      "Validation loss decreased (0.167816 --> 0.167016).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 9 cost time: 29.69990611076355\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 9, Steps 66 | train_loss=0.1908478 | val_loss=0.1671056 val_MAE=0.3132013 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 10 cost time: 29.94322967529297\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 10, Steps 66 | train_loss=0.1896439 | val_loss=0.1666744 val_MAE=0.3125429 |\n",
      "Validation loss decreased (0.167016 --> 0.166674).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : KW_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.183322012424469, mae:0.3192894458770752\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:2820.1391785764345, mae:39.601580368812456\n",
      "CSV saved → ./results/KW_WITHOUTLSTM_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (17304, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --root_path ./dataset/kw/ --data_path kw_dataset.csv --task_id KW_WITHOUTLSTM_MS --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 24 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ee96ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='TEMPERATURE_WITHOUTLSTM_MS_Wavelets', model='FEDformer', version='Wavelets', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/temperature/', data_path='temperature_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=24, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : TEMPERATURE_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 37.34700679779053\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.3620670 | val_loss=0.0520750 val_MAE=0.1810553 |\n",
      "Validation loss decreased (inf --> 0.052075).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 36.564937114715576\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.2294413 | val_loss=0.0705964 val_MAE=0.2145338 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 36.48810958862305\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.2174198 | val_loss=0.0557246 val_MAE=0.1839848 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 36.59520244598389\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.2073165 | val_loss=0.0633514 val_MAE=0.1967632 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.08078610897064209, mae:0.22187328338623047\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:0.6174910201233217, mae:0.6134115852817615\n",
      "CSV saved → ./results/TEMPERATURE_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : TEMPERATURE_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 36.73746609687805\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.3589273 | val_loss=0.0790658 val_MAE=0.2297287 |\n",
      "Validation loss decreased (inf --> 0.079066).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 36.21223974227905\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.2318102 | val_loss=0.0476580 val_MAE=0.1664983 |\n",
      "Validation loss decreased (0.079066 --> 0.047658).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 37.11917471885681\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.2124119 | val_loss=0.0605165 val_MAE=0.1962135 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 36.093448877334595\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.2038282 | val_loss=0.0536028 val_MAE=0.1788678 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 36.37173342704773\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.2008912 | val_loss=0.0592544 val_MAE=0.1898127 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.06951548904180527, mae:0.20351293683052063\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:0.5313436603170328, mae:0.5626508753009021\n",
      "CSV saved → ./results/TEMPERATURE_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : TEMPERATURE_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 36.7898805141449\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.3572779 | val_loss=0.0546769 val_MAE=0.1886317 |\n",
      "Validation loss decreased (inf --> 0.054677).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 36.19021129608154\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.2274067 | val_loss=0.0636859 val_MAE=0.1994241 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 36.54556393623352\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.2101463 | val_loss=0.0737608 val_MAE=0.2122615 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 35.95244216918945\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.2037062 | val_loss=0.0521935 val_MAE=0.1766672 |\n",
      "Validation loss decreased (0.054677 --> 0.052193).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 36.15521693229675\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.1972088 | val_loss=0.0549122 val_MAE=0.1810725 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 36.661346673965454\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.1949813 | val_loss=0.0532018 val_MAE=0.1782885 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 36.220672845840454\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.1940774 | val_loss=0.0548380 val_MAE=0.1814684 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.082001693546772, mae:0.2203109711408615\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:0.6267823952400299, mae:0.6090922627011722\n",
      "CSV saved → ./results/TEMPERATURE_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (17304, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --version Wavelets --root_path ./dataset/temperature/ --data_path temperature_dataset.csv --task_id TEMPERATURE_WITHOUTLSTM_MS_Wavelets --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 24 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09096b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='GHI_WITHOUTLSTM_MS_Wavelets', model='FEDformer', version='Wavelets', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/ghi/', data_path='ghi_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=24, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : GHI_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 37.478351354599\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.4811280 | val_loss=0.2790753 val_MAE=0.3754072 |\n",
      "Validation loss decreased (inf --> 0.279075).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 36.1379599571228\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.3446688 | val_loss=0.2754579 val_MAE=0.3653576 |\n",
      "Validation loss decreased (0.279075 --> 0.275458).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 36.49833130836487\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (0.275458 --> nan).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 37.67022657394409\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 36.60117530822754\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 37.27011823654175\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 36.44824576377869\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 8 cost time: 36.30714654922485\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 8, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 9 cost time: 36.92801856994629\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 9, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 10 cost time: 36.47490906715393\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 10, Steps 66 | train_loss=nan | val_loss=nan val_MAE=nan |\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : GHI_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:nan, mae:nan\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:nan, mae:nan\n",
      "CSV saved → ./results/GHI_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : GHI_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 36.63550615310669\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.5069738 | val_loss=0.2499864 val_MAE=0.3625863 |\n",
      "Validation loss decreased (inf --> 0.249986).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 36.04492473602295\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.3433927 | val_loss=0.2712581 val_MAE=0.3712313 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 36.05981254577637\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.3216877 | val_loss=0.2756297 val_MAE=0.3719040 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 37.250205993652344\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.3163723 | val_loss=0.2575093 val_MAE=0.3402111 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : GHI_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:nan, mae:nan\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:nan, mae:nan\n",
      "CSV saved → ./results/GHI_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : GHI_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 36.09550857543945\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.5015648 | val_loss=0.3286969 val_MAE=0.4221429 |\n",
      "Validation loss decreased (inf --> 0.328697).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 36.14806866645813\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.3464903 | val_loss=0.2532195 val_MAE=0.3528243 |\n",
      "Validation loss decreased (0.328697 --> 0.253220).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 36.02333688735962\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.3230932 | val_loss=0.3037779 val_MAE=0.3864929 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 36.261114835739136\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.3121477 | val_loss=0.2468152 val_MAE=0.3312647 |\n",
      "Validation loss decreased (0.253220 --> 0.246815).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 37.57056784629822\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.3067978 | val_loss=0.2612374 val_MAE=0.3400729 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 36.15690064430237\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.3023445 | val_loss=0.2487415 val_MAE=0.3305320 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 37.39025092124939\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.3010013 | val_loss=0.2643300 val_MAE=0.3417434 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : GHI_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.3024843633174896, mae:0.3627068102359772\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:19954.186144863354, mae:93.15823541285702\n",
      "CSV saved → ./results/GHI_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (17304, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --version Wavelets --root_path ./dataset/ghi/ --data_path ghi_dataset.csv --task_id GHI_WITHOUTLSTM_MS_Wavelets --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 24 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7d3353f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='KW_WITHOUTLSTM_MS_Wavelets', model='FEDformer', version='Wavelets', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/kw/', data_path='kw_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=24, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : KW_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 37.23657965660095\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.3418684 | val_loss=0.1976191 val_MAE=0.3440946 |\n",
      "Validation loss decreased (inf --> 0.197619).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 36.390565395355225\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.2129454 | val_loss=0.2317142 val_MAE=0.3741979 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 37.06216621398926\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.1926253 | val_loss=0.1760611 val_MAE=0.3238981 |\n",
      "Validation loss decreased (0.197619 --> 0.176061).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 36.34463286399841\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.1806590 | val_loss=0.1756870 val_MAE=0.3195244 |\n",
      "Validation loss decreased (0.176061 --> 0.175687).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 38.135191917419434\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.1762264 | val_loss=0.1665117 val_MAE=0.3100588 |\n",
      "Validation loss decreased (0.175687 --> 0.166512).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 36.35071921348572\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.1728143 | val_loss=0.1637251 val_MAE=0.3074725 |\n",
      "Validation loss decreased (0.166512 --> 0.163725).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 36.450045108795166\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.1712733 | val_loss=0.1682467 val_MAE=0.3133320 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 8 cost time: 36.27971649169922\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 8, Steps 66 | train_loss=0.1703604 | val_loss=0.1650212 val_MAE=0.3092986 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 9 cost time: 36.66219639778137\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 9, Steps 66 | train_loss=0.1692727 | val_loss=0.1662179 val_MAE=0.3109338 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : KW_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.17379693686962128, mae:0.3138769567012787\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:2673.610121860056, mae:38.93026923816316\n",
      "CSV saved → ./results/KW_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : KW_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 37.4907603263855\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.4061640 | val_loss=0.1876977 val_MAE=0.3343074 |\n",
      "Validation loss decreased (inf --> 0.187698).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 36.1199893951416\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.2189828 | val_loss=0.1931503 val_MAE=0.3405402 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 36.186182498931885\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.1970183 | val_loss=0.1827525 val_MAE=0.3255049 |\n",
      "Validation loss decreased (0.187698 --> 0.182752).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 36.326855421066284\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.1880805 | val_loss=0.1656895 val_MAE=0.3078509 |\n",
      "Validation loss decreased (0.182752 --> 0.165689).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 36.66552734375\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.1827415 | val_loss=0.1706975 val_MAE=0.3164871 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 36.72016739845276\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.1794668 | val_loss=0.1684402 val_MAE=0.3135597 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 36.42856168746948\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.1779106 | val_loss=0.1664523 val_MAE=0.3108632 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : KW_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.18106205761432648, mae:0.31527015566825867\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:2785.373500756319, mae:39.103070059495856\n",
      "CSV saved → ./results/KW_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : KW_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 36.60004639625549\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.3663865 | val_loss=0.1944200 val_MAE=0.3393106 |\n",
      "Validation loss decreased (inf --> 0.194420).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 36.38276720046997\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.2139670 | val_loss=0.1889538 val_MAE=0.3360808 |\n",
      "Validation loss decreased (0.194420 --> 0.188954).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 36.60002875328064\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.1941188 | val_loss=0.1639630 val_MAE=0.3110473 |\n",
      "Validation loss decreased (0.188954 --> 0.163963).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 36.93945550918579\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.1815643 | val_loss=0.1616368 val_MAE=0.3070841 |\n",
      "Validation loss decreased (0.163963 --> 0.161637).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 36.38698053359985\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.1775664 | val_loss=0.1692868 val_MAE=0.3133632 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 36.98883843421936\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.1748599 | val_loss=0.1647824 val_MAE=0.3087067 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 36.35501408576965\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.1721182 | val_loss=0.1668879 val_MAE=0.3121852 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : KW_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.17084725201129913, mae:0.3113259971141815\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:2628.2337871030513, mae:38.61387342815896\n",
      "CSV saved → ./results/KW_WITHOUTLSTM_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (17304, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --version Wavelets --root_path ./dataset/kw/ --data_path kw_dataset.csv --task_id KW_WITHOUTLSTM_MS_Wavelets --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 24 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9fe93b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='TEMPERATURE_WITHOUTLSTM1Hour_MS', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/temperature/', data_path='temperature_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=1, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=6, index_q=[0, 1, 2, 3, 4, 5]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : TEMPERATURE_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 29.75292944908142\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.1162041 | val_loss=0.0126416 val_MAE=0.0919361 |\n",
      "Validation loss decreased (inf --> 0.012642).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 28.713918924331665\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0342174 | val_loss=0.0099044 val_MAE=0.0816831 |\n",
      "Validation loss decreased (0.012642 --> 0.009904).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 29.20020627975464\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0280419 | val_loss=0.0058560 val_MAE=0.0601365 |\n",
      "Validation loss decreased (0.009904 --> 0.005856).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 28.80586528778076\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0231688 | val_loss=0.0077805 val_MAE=0.0703148 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 28.743562698364258\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0213348 | val_loss=0.0060480 val_MAE=0.0614960 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 28.849764108657837\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0218265 | val_loss=0.0064742 val_MAE=0.0652181 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.008019933477044106, mae:0.06789155304431915\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:0.06130059958367665, mae:0.18769933747915538\n",
      "CSV saved → ./results/TEMPERATURE_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=6, index_q=[0, 1, 2, 3, 4, 5]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : TEMPERATURE_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 29.153665781021118\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.1349639 | val_loss=0.0113555 val_MAE=0.0842215 |\n",
      "Validation loss decreased (inf --> 0.011355).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 28.578943490982056\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0351389 | val_loss=0.0090566 val_MAE=0.0770473 |\n",
      "Validation loss decreased (0.011355 --> 0.009057).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 29.22866988182068\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0268567 | val_loss=0.0092826 val_MAE=0.0758584 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 28.916062355041504\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0240997 | val_loss=0.0076276 val_MAE=0.0699198 |\n",
      "Validation loss decreased (0.009057 --> 0.007628).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 29.014601469039917\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0222032 | val_loss=0.0068314 val_MAE=0.0659645 |\n",
      "Validation loss decreased (0.007628 --> 0.006831).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 28.950212478637695\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0196566 | val_loss=0.0059408 val_MAE=0.0616202 |\n",
      "Validation loss decreased (0.006831 --> 0.005941).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 29.466581344604492\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.0210395 | val_loss=0.0067190 val_MAE=0.0649189 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 28.663626432418823\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.0209861 | val_loss=0.0058276 val_MAE=0.0603845 |\n",
      "Validation loss decreased (0.005941 --> 0.005828).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 29.445509672164917\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.0202978 | val_loss=0.0056379 val_MAE=0.0594845 |\n",
      "Validation loss decreased (0.005828 --> 0.005638).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 10 cost time: 28.614561319351196\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 10, Steps 67 | train_loss=0.0207157 | val_loss=0.0057256 val_MAE=0.0600163 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.007620965130627155, mae:0.06685597449541092\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:0.058251076526216014, mae:0.18483627788797755\n",
      "CSV saved → ./results/TEMPERATURE_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=6, index_q=[0, 1, 2, 3, 4, 5]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : TEMPERATURE_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 28.893298149108887\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.0890468 | val_loss=0.0128776 val_MAE=0.0933343 |\n",
      "Validation loss decreased (inf --> 0.012878).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 28.71658682823181\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0340095 | val_loss=0.0103645 val_MAE=0.0823409 |\n",
      "Validation loss decreased (0.012878 --> 0.010364).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 29.456379890441895\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0262715 | val_loss=0.0119535 val_MAE=0.0908760 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 28.656939268112183\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0236881 | val_loss=0.0087262 val_MAE=0.0781896 |\n",
      "Validation loss decreased (0.010364 --> 0.008726).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 29.316667318344116\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0216316 | val_loss=0.0093460 val_MAE=0.0785806 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 28.81502866744995\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0200729 | val_loss=0.0063569 val_MAE=0.0643348 |\n",
      "Validation loss decreased (0.008726 --> 0.006357).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 29.050097227096558\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.0202654 | val_loss=0.0064040 val_MAE=0.0650747 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 28.886133193969727\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.0204356 | val_loss=0.0065523 val_MAE=0.0649134 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 31.601129055023193\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.0198057 | val_loss=0.0063719 val_MAE=0.0649215 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.009256326593458652, mae:0.07436749339103699\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:0.07075101406561646, mae:0.20560331382108907\n",
      "CSV saved → ./results/TEMPERATURE_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (744, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --root_path ./dataset/temperature/ --data_path temperature_dataset.csv --task_id TEMPERATURE_WITHOUTLSTM1Hour_MS --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 1 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20546f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='GHI_WITHOUTLSTM1Hour_MS', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/ghi/', data_path='ghi_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=1, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=6, index_q=[0, 1, 2, 3, 4, 5]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : GHI_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 32.76388645172119\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.2656695 | val_loss=0.1590494 val_MAE=0.2651855 |\n",
      "Validation loss decreased (inf --> 0.159049).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 31.75179958343506\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.1793289 | val_loss=0.1562515 val_MAE=0.2685872 |\n",
      "Validation loss decreased (0.159049 --> 0.156251).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 30.94897484779358\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.1614667 | val_loss=0.1557001 val_MAE=0.2715742 |\n",
      "Validation loss decreased (0.156251 --> 0.155700).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 30.889568090438843\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.1601344 | val_loss=0.1445715 val_MAE=0.2301521 |\n",
      "Validation loss decreased (0.155700 --> 0.144571).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 31.021249055862427\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.1514808 | val_loss=0.1365308 val_MAE=0.2176878 |\n",
      "Validation loss decreased (0.144571 --> 0.136531).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 31.04244065284729\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.1504972 | val_loss=0.1370930 val_MAE=0.2195637 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 30.904476404190063\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.1460652 | val_loss=0.1435093 val_MAE=0.2310780 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 31.321385860443115\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.1503433 | val_loss=0.1405135 val_MAE=0.2254828 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : GHI_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.15895254909992218, mae:0.23484328389167786\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:10485.72731521997, mae:60.3175454184494\n",
      "CSV saved → ./results/GHI_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=6, index_q=[0, 1, 2, 3, 4, 5]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : GHI_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 30.839423418045044\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.2715277 | val_loss=0.1544244 val_MAE=0.2489741 |\n",
      "Validation loss decreased (inf --> 0.154424).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 31.14950466156006\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.1781871 | val_loss=0.1526732 val_MAE=0.2274493 |\n",
      "Validation loss decreased (0.154424 --> 0.152673).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 31.164472103118896\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.1629746 | val_loss=0.1432380 val_MAE=0.2376585 |\n",
      "Validation loss decreased (0.152673 --> 0.143238).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 31.187159538269043\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.1546089 | val_loss=0.1382754 val_MAE=0.2208183 |\n",
      "Validation loss decreased (0.143238 --> 0.138275).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 31.490956783294678\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.1498350 | val_loss=0.1530683 val_MAE=0.2413820 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 30.858091115951538\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.1503419 | val_loss=0.1399610 val_MAE=0.2244571 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 30.74936842918396\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.1444373 | val_loss=0.1396200 val_MAE=0.2235395 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : GHI_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.16081295907497406, mae:0.23878103494644165\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:10608.452996640779, mae:61.32892770567681\n",
      "CSV saved → ./results/GHI_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=6, index_q=[0, 1, 2, 3, 4, 5]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : GHI_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 30.481868267059326\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.2451847 | val_loss=0.1598065 val_MAE=0.2608302 |\n",
      "Validation loss decreased (inf --> 0.159807).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 30.90596652030945\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.1886147 | val_loss=0.1686077 val_MAE=0.2901100 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 30.546509504318237\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.1618863 | val_loss=0.1410045 val_MAE=0.2241520 |\n",
      "Validation loss decreased (0.159807 --> 0.141005).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 31.252797603607178\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.1541196 | val_loss=0.1451681 val_MAE=0.2429206 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 30.6611225605011\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.1506197 | val_loss=0.1444647 val_MAE=0.2318582 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 30.95180034637451\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.1441885 | val_loss=0.1437194 val_MAE=0.2312397 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : GHI_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.1629350483417511, mae:0.2438415139913559\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:10748.442482823288, mae:62.62867480473791\n",
      "CSV saved → ./results/GHI_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (744, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --root_path ./dataset/ghi/ --data_path ghi_dataset.csv --task_id GHI_WITHOUTLSTM1Hour_MS --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 1 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a83abe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='KW_WITHOUTLSTM1Hour_MS', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/kw/', data_path='kw_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=1, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=6, index_q=[0, 1, 2, 3, 4, 5]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : KW_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 31.74890398979187\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.1643341 | val_loss=0.0944145 val_MAE=0.2427880 |\n",
      "Validation loss decreased (inf --> 0.094414).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 30.89921236038208\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0784097 | val_loss=0.0693404 val_MAE=0.2075790 |\n",
      "Validation loss decreased (0.094414 --> 0.069340).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 31.12588405609131\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0624195 | val_loss=0.0629910 val_MAE=0.2004232 |\n",
      "Validation loss decreased (0.069340 --> 0.062991).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 30.643969774246216\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0574153 | val_loss=0.0496886 val_MAE=0.1752036 |\n",
      "Validation loss decreased (0.062991 --> 0.049689).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 30.946661472320557\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0555434 | val_loss=0.0444263 val_MAE=0.1645991 |\n",
      "Validation loss decreased (0.049689 --> 0.044426).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 31.19232487678528\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0527836 | val_loss=0.0468649 val_MAE=0.1699496 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 31.37938666343689\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.0513025 | val_loss=0.0491954 val_MAE=0.1740831 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 31.233080625534058\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.0496452 | val_loss=0.0483541 val_MAE=0.1719255 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : KW_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.04814816638827324, mae:0.16379640996456146\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:740.6887235799795, mae:20.315728173602132\n",
      "CSV saved → ./results/KW_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=6, index_q=[0, 1, 2, 3, 4, 5]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : KW_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 31.88832139968872\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.1381751 | val_loss=0.0870473 val_MAE=0.2343870 |\n",
      "Validation loss decreased (inf --> 0.087047).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 30.89949631690979\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0677908 | val_loss=0.0787819 val_MAE=0.2254047 |\n",
      "Validation loss decreased (0.087047 --> 0.078782).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 31.079803228378296\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0597029 | val_loss=0.0488887 val_MAE=0.1723285 |\n",
      "Validation loss decreased (0.078782 --> 0.048889).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 31.086374521255493\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0551572 | val_loss=0.0416749 val_MAE=0.1568255 |\n",
      "Validation loss decreased (0.048889 --> 0.041675).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 31.366531372070312\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0551483 | val_loss=0.0538111 val_MAE=0.1809655 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 30.972856998443604\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0497866 | val_loss=0.0550972 val_MAE=0.1830473 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 31.166780948638916\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.0522452 | val_loss=0.0498794 val_MAE=0.1735401 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : KW_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.04599320888519287, mae:0.16050198674201965\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:707.5378397153694, mae:19.907118269453555\n",
      "CSV saved → ./results/KW_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=6, index_q=[0, 1, 2, 3, 4, 5]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : KW_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 30.823366165161133\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.1627191 | val_loss=0.1222656 val_MAE=0.2722879 |\n",
      "Validation loss decreased (inf --> 0.122266).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 30.685376405715942\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0741133 | val_loss=0.0695755 val_MAE=0.2080211 |\n",
      "Validation loss decreased (0.122266 --> 0.069575).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 31.110966444015503\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0578229 | val_loss=0.0552823 val_MAE=0.1816203 |\n",
      "Validation loss decreased (0.069575 --> 0.055282).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 30.927581548690796\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0553131 | val_loss=0.0479616 val_MAE=0.1703301 |\n",
      "Validation loss decreased (0.055282 --> 0.047962).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 31.44843864440918\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0532145 | val_loss=0.0526281 val_MAE=0.1787284 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 30.964081048965454\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0508981 | val_loss=0.0449793 val_MAE=0.1635114 |\n",
      "Validation loss decreased (0.047962 --> 0.044979).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 30.90321969985962\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.0505143 | val_loss=0.0475137 val_MAE=0.1690576 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 30.857926607131958\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.0511393 | val_loss=0.0481715 val_MAE=0.1703434 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 31.056929349899292\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.0498120 | val_loss=0.0452484 val_MAE=0.1648450 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : KW_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.04928439110517502, mae:0.1651730239391327\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:758.167914725625, mae:20.48646864558813\n",
      "CSV saved → ./results/KW_WITHOUTLSTM1Hour_MS_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (744, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --root_path ./dataset/kw/ --data_path kw_dataset.csv --task_id KW_WITHOUTLSTM1Hour_MS --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 1 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a88be04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='TEMPERATURE_WITHOUTLSTM1Hour_MS_Wavelets', model='FEDformer', version='Wavelets', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/temperature/', data_path='temperature_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=1, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : TEMPERATURE_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 37.419718742370605\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.1066764 | val_loss=0.0159467 val_MAE=0.0995952 |\n",
      "Validation loss decreased (inf --> 0.015947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 36.56774854660034\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0313321 | val_loss=0.0133111 val_MAE=0.0914354 |\n",
      "Validation loss decreased (0.015947 --> 0.013311).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 36.14964580535889\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0207546 | val_loss=0.0080721 val_MAE=0.0733811 |\n",
      "Validation loss decreased (0.013311 --> 0.008072).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 36.211766719818115\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0162634 | val_loss=0.0049157 val_MAE=0.0556711 |\n",
      "Validation loss decreased (0.008072 --> 0.004916).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 36.40496516227722\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0150339 | val_loss=0.0041927 val_MAE=0.0497584 |\n",
      "Validation loss decreased (0.004916 --> 0.004193).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 36.34135627746582\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0145990 | val_loss=0.0039628 val_MAE=0.0483562 |\n",
      "Validation loss decreased (0.004193 --> 0.003963).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 36.66951560974121\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.0142445 | val_loss=0.0039612 val_MAE=0.0487429 |\n",
      "Validation loss decreased (0.003963 --> 0.003961).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 36.41891574859619\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.0136018 | val_loss=0.0036000 val_MAE=0.0466379 |\n",
      "Validation loss decreased (0.003961 --> 0.003600).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 36.2762246131897\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.0140388 | val_loss=0.0038296 val_MAE=0.0482009 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 10 cost time: 36.49920177459717\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 10, Steps 67 | train_loss=0.0132631 | val_loss=0.0035901 val_MAE=0.0464207 |\n",
      "Validation loss decreased (0.003600 --> 0.003590).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.004237787798047066, mae:0.04970438405871391\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:0.03239165703962714, mae:0.13741737883186758\n",
      "CSV saved → ./results/TEMPERATURE_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : TEMPERATURE_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 36.63630938529968\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.1604475 | val_loss=0.0141585 val_MAE=0.0963109 |\n",
      "Validation loss decreased (inf --> 0.014159).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 36.04707479476929\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0303391 | val_loss=0.0177402 val_MAE=0.1087223 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 36.09984874725342\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0211976 | val_loss=0.0065852 val_MAE=0.0634751 |\n",
      "Validation loss decreased (0.014159 --> 0.006585).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 35.92801594734192\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0170720 | val_loss=0.0057681 val_MAE=0.0592731 |\n",
      "Validation loss decreased (0.006585 --> 0.005768).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 36.100971698760986\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0158455 | val_loss=0.0056019 val_MAE=0.0611735 |\n",
      "Validation loss decreased (0.005768 --> 0.005602).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 36.03032159805298\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0145030 | val_loss=0.0041601 val_MAE=0.0504158 |\n",
      "Validation loss decreased (0.005602 --> 0.004160).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 35.9400110244751\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.0143592 | val_loss=0.0044238 val_MAE=0.0523596 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 36.073766469955444\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.0140719 | val_loss=0.0047153 val_MAE=0.0543968 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 36.10211896896362\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.0140348 | val_loss=0.0042435 val_MAE=0.0513742 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.005431580822914839, mae:0.056904423981904984\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:0.04151645228507862, mae:0.15732327719219236\n",
      "CSV saved → ./results/TEMPERATURE_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : TEMPERATURE_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 36.311118602752686\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.1017848 | val_loss=0.0091200 val_MAE=0.0753643 |\n",
      "Validation loss decreased (inf --> 0.009120).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 36.33723521232605\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0299621 | val_loss=0.0106088 val_MAE=0.0854196 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 36.04621601104736\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0188143 | val_loss=0.0081633 val_MAE=0.0722715 |\n",
      "Validation loss decreased (0.009120 --> 0.008163).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 36.11933183670044\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0155819 | val_loss=0.0050411 val_MAE=0.0570231 |\n",
      "Validation loss decreased (0.008163 --> 0.005041).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 36.20285892486572\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0145659 | val_loss=0.0037779 val_MAE=0.0494105 |\n",
      "Validation loss decreased (0.005041 --> 0.003778).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 36.4048433303833\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0140582 | val_loss=0.0038698 val_MAE=0.0505061 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 36.02505445480347\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.0127079 | val_loss=0.0030905 val_MAE=0.0443317 |\n",
      "Validation loss decreased (0.003778 --> 0.003091).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 36.47458267211914\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.0126527 | val_loss=0.0032445 val_MAE=0.0445150 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 36.068944454193115\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.0137643 | val_loss=0.0031565 val_MAE=0.0443511 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 10 cost time: 36.0281822681427\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 10, Steps 67 | train_loss=0.0132637 | val_loss=0.0031406 val_MAE=0.0441867 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.0034718820825219154, mae:0.04555413872003555\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:0.02653743456240134, mae:0.12594324230285645\n",
      "CSV saved → ./results/TEMPERATURE_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (744, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --version Wavelets --root_path ./dataset/temperature/ --data_path temperature_dataset.csv --task_id TEMPERATURE_WITHOUTLSTM1Hour_MS_Wavelets --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 1 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6521a8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='GHI_WITHOUTLSTM1Hour_MS_Wavelets', model='FEDformer', version='Wavelets', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/ghi/', data_path='ghi_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=1, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : GHI_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 37.27918601036072\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.2570306 | val_loss=0.1717822 val_MAE=0.2930179 |\n",
      "Validation loss decreased (inf --> 0.171782).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 36.60088920593262\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.1906551 | val_loss=0.1763846 val_MAE=0.2824396 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 36.181272983551025\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.1659283 | val_loss=0.1458374 val_MAE=0.2301495 |\n",
      "Validation loss decreased (0.171782 --> 0.145837).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 36.479790687561035\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.1518719 | val_loss=0.1425978 val_MAE=0.2207773 |\n",
      "Validation loss decreased (0.145837 --> 0.142598).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 36.148438930511475\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.1475681 | val_loss=0.1389196 val_MAE=0.2223201 |\n",
      "Validation loss decreased (0.142598 --> 0.138920).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 36.41120934486389\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.1426860 | val_loss=0.1345376 val_MAE=0.2116382 |\n",
      "Validation loss decreased (0.138920 --> 0.134538).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 35.82264447212219\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.1409448 | val_loss=0.1359134 val_MAE=0.2141318 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 36.6487512588501\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.1379837 | val_loss=0.1374230 val_MAE=0.2175182 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 36.137133836746216\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.1425119 | val_loss=0.1373306 val_MAE=0.2180973 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : GHI_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.15607169270515442, mae:0.22488197684288025\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:10295.683690405533, mae:57.75907050143872\n",
      "CSV saved → ./results/GHI_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : GHI_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 35.89399266242981\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.3154963 | val_loss=0.1477917 val_MAE=0.2489983 |\n",
      "Validation loss decreased (inf --> 0.147792).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 35.82739472389221\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.1775229 | val_loss=0.1911297 val_MAE=0.2944755 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 35.531163454055786\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.1695046 | val_loss=0.1417554 val_MAE=0.2129151 |\n",
      "Validation loss decreased (0.147792 --> 0.141755).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 35.75677943229675\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.1517653 | val_loss=0.1370076 val_MAE=0.2193367 |\n",
      "Validation loss decreased (0.141755 --> 0.137008).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 35.91135787963867\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.1459958 | val_loss=0.1365485 val_MAE=0.2188708 |\n",
      "Validation loss decreased (0.137008 --> 0.136548).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 35.97525501251221\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.1452123 | val_loss=0.1357371 val_MAE=0.2166442 |\n",
      "Validation loss decreased (0.136548 --> 0.135737).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 36.202473640441895\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.1421895 | val_loss=0.1343608 val_MAE=0.2119919 |\n",
      "Validation loss decreased (0.135737 --> 0.134361).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 35.891876220703125\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.1414748 | val_loss=0.1344778 val_MAE=0.2129450 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 36.626896142959595\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.1444192 | val_loss=0.1346010 val_MAE=0.2140611 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 10 cost time: 36.1555597782135\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 10, Steps 67 | train_loss=0.1371728 | val_loss=0.1345572 val_MAE=0.2137761 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : GHI_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.15696732699871063, mae:0.22715993225574493\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:10354.766330658142, mae:58.34414364798388\n",
      "CSV saved → ./results/GHI_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : GHI_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 36.26217794418335\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.3033843 | val_loss=0.1521281 val_MAE=0.2567343 |\n",
      "Validation loss decreased (inf --> 0.152128).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 36.00971055030823\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.1936467 | val_loss=0.2563839 val_MAE=0.3515841 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 35.8957781791687\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.1712594 | val_loss=0.1479430 val_MAE=0.2444666 |\n",
      "Validation loss decreased (0.152128 --> 0.147943).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 36.2669095993042\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.1489757 | val_loss=0.1400167 val_MAE=0.2273593 |\n",
      "Validation loss decreased (0.147943 --> 0.140017).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 36.16795110702515\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.1457672 | val_loss=0.1409324 val_MAE=0.2304214 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 36.08952808380127\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.1447108 | val_loss=0.1361771 val_MAE=0.2149629 |\n",
      "Validation loss decreased (0.140017 --> 0.136177).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 35.355027198791504\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.1430711 | val_loss=0.1374376 val_MAE=0.2177375 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 35.98871994018555\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.1424540 | val_loss=0.1366408 val_MAE=0.2153141 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 36.52485513687134\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.1418584 | val_loss=0.1366794 val_MAE=0.2158480 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : GHI_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.15847504138946533, mae:0.22888822853565216\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:10454.226934239794, mae:58.788041189506686\n",
      "CSV saved → ./results/GHI_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (744, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --version Wavelets --root_path ./dataset/ghi/ --data_path ghi_dataset.csv --task_id GHI_WITHOUTLSTM1Hour_MS_Wavelets --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 1 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02b6d554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='KW_WITHOUTLSTM1Hour_MS_Wavelets', model='FEDformer', version='Wavelets', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/kw/', data_path='kw_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=1, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : KW_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 36.81486201286316\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.1349494 | val_loss=0.0611940 val_MAE=0.1948940 |\n",
      "Validation loss decreased (inf --> 0.061194).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 36.28720045089722\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0726981 | val_loss=0.1025253 val_MAE=0.2646212 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 36.61692976951599\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0602142 | val_loss=0.0564114 val_MAE=0.1821591 |\n",
      "Validation loss decreased (0.061194 --> 0.056411).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 36.3279447555542\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0493976 | val_loss=0.0385691 val_MAE=0.1494083 |\n",
      "Validation loss decreased (0.056411 --> 0.038569).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 36.29348564147949\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0481575 | val_loss=0.0403045 val_MAE=0.1539061 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 36.11713194847107\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0468516 | val_loss=0.0393772 val_MAE=0.1521605 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 36.06410336494446\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.0450463 | val_loss=0.0378336 val_MAE=0.1488093 |\n",
      "Validation loss decreased (0.038569 --> 0.037834).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 36.50526428222656\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.0424781 | val_loss=0.0378556 val_MAE=0.1482102 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 36.053475856781006\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.0464292 | val_loss=0.0374192 val_MAE=0.1474031 |\n",
      "Validation loss decreased (0.037834 --> 0.037419).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 10 cost time: 36.91070818901062\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 10, Steps 67 | train_loss=0.0444549 | val_loss=0.0379080 val_MAE=0.1484915 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : KW_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.039329756051301956, mae:0.14685136079788208\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:605.0304274691249, mae:18.21402596213088\n",
      "CSV saved → ./results/KW_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : KW_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 36.07189583778381\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.1745755 | val_loss=0.1191826 val_MAE=0.2764009 |\n",
      "Validation loss decreased (inf --> 0.119183).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 35.97791862487793\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0670860 | val_loss=0.0477739 val_MAE=0.1724735 |\n",
      "Validation loss decreased (0.119183 --> 0.047774).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 36.14481449127197\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0534512 | val_loss=0.0535275 val_MAE=0.1822486 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 35.84250354766846\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0504970 | val_loss=0.0360401 val_MAE=0.1456758 |\n",
      "Validation loss decreased (0.047774 --> 0.036040).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 36.42595815658569\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0475118 | val_loss=0.0363153 val_MAE=0.1438472 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 35.81286263465881\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0460236 | val_loss=0.0374212 val_MAE=0.1470172 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 35.9660587310791\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.0450756 | val_loss=0.0402471 val_MAE=0.1529182 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : KW_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.03878038749098778, mae:0.1476972997188568\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:596.5792155155002, mae:18.318949301902467\n",
      "CSV saved → ./results/KW_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (744, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 6\n",
      ">>>>>>>start training : KW_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2160\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 744\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 1 cost time: 36.26341986656189\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 1, Steps 67 | train_loss=0.1745181 | val_loss=0.0659237 val_MAE=0.2018374 |\n",
      "Validation loss decreased (inf --> 0.065924).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 2 cost time: 35.68023228645325\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 2, Steps 67 | train_loss=0.0666676 | val_loss=0.0562452 val_MAE=0.1883576 |\n",
      "Validation loss decreased (0.065924 --> 0.056245).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 3 cost time: 35.84006333351135\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 3, Steps 67 | train_loss=0.0539303 | val_loss=0.0450248 val_MAE=0.1670272 |\n",
      "Validation loss decreased (0.056245 --> 0.045025).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 4 cost time: 35.86683654785156\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 4, Steps 67 | train_loss=0.0495207 | val_loss=0.0429808 val_MAE=0.1601958 |\n",
      "Validation loss decreased (0.045025 --> 0.042981).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 5 cost time: 35.89766526222229\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 5, Steps 67 | train_loss=0.0477733 | val_loss=0.0460957 val_MAE=0.1680490 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 6 cost time: 36.13390827178955\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 6, Steps 67 | train_loss=0.0470473 | val_loss=0.0359042 val_MAE=0.1454834 |\n",
      "Validation loss decreased (0.042981 --> 0.035904).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 7 cost time: 37.677796840667725\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 7, Steps 67 | train_loss=0.0446658 | val_loss=0.0372327 val_MAE=0.1479864 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 8 cost time: 36.37267827987671\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 8, Steps 67 | train_loss=0.0454600 | val_loss=0.0366405 val_MAE=0.1471281 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 1, 1]) outputs torch.Size([32, 1, 1])\n",
      "Epoch: 9 cost time: 36.142757177352905\n",
      "output shape: torch.Size([8, 1, 1])\n",
      "label shape: torch.Size([8, 1, 1])\n",
      "Epoch 9, Steps 67 | train_loss=0.0468696 | val_loss=0.0382474 val_MAE=0.1500897 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 1, 1])\n",
      "label shape: torch.Size([32, 1, 1])\n",
      ">>>>>>>testing : KW_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 744\n",
      "output shape: (8, 1, 1)\n",
      "label shape: (8, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "test shape: (744, 1, 1) (744, 1, 1)\n",
      "mse:0.03848075866699219, mae:0.14671234786510468\n",
      "preds shape: (744, 1, 1)\n",
      "preds_2d shape: (744, 1)\n",
      "trues shape: (744, 1, 1)\n",
      "trues_2d shape: (744, 1)\n",
      "Inverse‐scaled mse:591.9698354117859, mae:18.19678531017476\n",
      "CSV saved → ./results/KW_WITHOUTLSTM1Hour_MS_Wavelets_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_2/pred_vs_true.csv | shape: (744, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --version Wavelets --root_path ./dataset/kw/ --data_path kw_dataset.csv --task_id KW_WITHOUTLSTM1Hour_MS_Wavelets --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 1 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 3 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f39eabd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='GHI_WITHOUTLSTM_MS_Wavelets_2', model='FEDformer', version='Wavelets', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/ghi/', data_path='ghi_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=24, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : GHI_WITHOUTLSTM_MS_Wavelets_2_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 40.207574129104614\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.4811029 | val_loss=0.2790647 val_MAE=0.3754059 |\n",
      "Validation loss decreased (inf --> 0.279065).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 38.980048418045044\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.3446584 | val_loss=0.2753598 val_MAE=0.3652515 |\n",
      "Validation loss decreased (0.279065 --> 0.275360).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 39.597498178482056\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.3205073 | val_loss=0.2625497 val_MAE=0.3432261 |\n",
      "Validation loss decreased (0.275360 --> 0.262550).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 38.72203707695007\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.3145600 | val_loss=0.2425389 val_MAE=0.3252239 |\n",
      "Validation loss decreased (0.262550 --> 0.242539).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 38.79675531387329\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.3083992 | val_loss=0.2654548 val_MAE=0.3412919 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 38.75271487236023\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.3028525 | val_loss=0.2596019 val_MAE=0.3365093 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 40.230358600616455\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.3018634 | val_loss=0.2647437 val_MAE=0.3428445 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : GHI_WITHOUTLSTM_MS_Wavelets_2_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.2956412434577942, mae:0.3578636646270752\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:19502.759891789246, mae:91.91430546958371\n",
      "CSV saved → ./results/GHI_WITHOUTLSTM_MS_Wavelets_2_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (17304, 3)\n",
      "Use GPU: cuda:0\n",
      "base legendre\n",
      "base legendre\n",
      "base legendre\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "corss fourier correlation used!\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : GHI_WITHOUTLSTM_MS_Wavelets_2_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 39.500152587890625\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.4987755 | val_loss=0.2860837 val_MAE=0.3751860 |\n",
      "Validation loss decreased (inf --> 0.286084).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 38.58947563171387\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.3419469 | val_loss=0.2678284 val_MAE=0.3572160 |\n",
      "Validation loss decreased (0.286084 --> 0.267828).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 38.6133234500885\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.3234237 | val_loss=0.3431724 val_MAE=0.4148050 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 39.14461016654968\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.3137191 | val_loss=0.2416119 val_MAE=0.3320508 |\n",
      "Validation loss decreased (0.267828 --> 0.241612).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 38.65033459663391\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.3067367 | val_loss=0.2687743 val_MAE=0.3467289 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 39.43014049530029\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.3044477 | val_loss=0.2581554 val_MAE=0.3361490 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 39.63614773750305\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.3044209 | val_loss=0.2601449 val_MAE=0.3384092 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : GHI_WITHOUTLSTM_MS_Wavelets_2_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.30006861686706543, mae:0.3646508753299713\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:19794.82380512305, mae:93.6575393863219\n",
      "CSV saved → ./results/GHI_WITHOUTLSTM_MS_Wavelets_2_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_1/pred_vs_true.csv | shape: (17304, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --version Wavelets --root_path ./dataset/ghi/ --data_path ghi_dataset.csv --task_id GHI_WITHOUTLSTM_MS_Wavelets_2 --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 24 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 2 --use_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c21858d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='TEMPERATURE_WITHOUTLSTM_MS_2', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/temperature/', data_path='temperature_dataset.csv', features='MS', target='OT', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=24, label_len=24, pred_len=24, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des=\"'Exp'\", loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=18, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "modes_kv=12, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "enc_modes: 12, dec_modes: 18\n",
      ">>>>>>>start training : TEMPERATURE_WITHOUTLSTM_MS_2_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Train | Start: 2019-04-01 00:00:00 | End: 2019-06-30 23:00:00 | Total: 2184\n",
      "train 2137\n",
      "Val | Start: 2019-06-30 00:00:00 | End: 2019-07-31 23:00:00 | Total: 768\n",
      "val 721\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 1 cost time: 32.91359043121338\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 1, Steps 66 | train_loss=0.3097294 | val_loss=0.0568320 val_MAE=0.1870241 |\n",
      "Validation loss decreased (inf --> 0.056832).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 2 cost time: 31.75264620780945\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 2, Steps 66 | train_loss=0.2547330 | val_loss=0.0484958 val_MAE=0.1724601 |\n",
      "Validation loss decreased (0.056832 --> 0.048496).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 3 cost time: 31.663825273513794\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 3, Steps 66 | train_loss=0.2313002 | val_loss=0.0534241 val_MAE=0.1823513 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 4 cost time: 33.0998957157135\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 4, Steps 66 | train_loss=0.2176396 | val_loss=0.0493129 val_MAE=0.1749869 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 5 cost time: 31.480048656463623\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 5, Steps 66 | train_loss=0.2085923 | val_loss=0.0463881 val_MAE=0.1693713 |\n",
      "Validation loss decreased (0.048496 --> 0.046388).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 6 cost time: 31.626939058303833\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 6, Steps 66 | train_loss=0.2034397 | val_loss=0.0450426 val_MAE=0.1660539 |\n",
      "Validation loss decreased (0.046388 --> 0.045043).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 7 cost time: 31.67956829071045\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 7, Steps 66 | train_loss=0.2007234 | val_loss=0.0468680 val_MAE=0.1689748 |\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 8 cost time: 32.23344588279724\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 8, Steps 66 | train_loss=0.2019921 | val_loss=0.0466454 val_MAE=0.1689798 |\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "batch_x torch.Size([32, 24, 3]) batch_y torch.Size([32, 24, 1]) outputs torch.Size([32, 24, 1])\n",
      "Epoch: 9 cost time: 31.873013496398926\n",
      "output shape: torch.Size([17, 24, 1])\n",
      "label shape: torch.Size([17, 24, 1])\n",
      "Epoch 9, Steps 66 | train_loss=0.1999433 | val_loss=0.0465914 val_MAE=0.1686468 |\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "output shape: torch.Size([32, 24, 1])\n",
      "label shape: torch.Size([32, 24, 1])\n",
      ">>>>>>>testing : TEMPERATURE_WITHOUTLSTM_MS_2_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Test | Start: 2019-07-31 00:00:00 | End: 2019-08-31 23:00:00 | Total: 768\n",
      "test 721\n",
      "output shape: (17, 24, 1)\n",
      "label shape: (17, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "test shape: (721, 24, 1) (721, 24, 1)\n",
      "mse:0.07126092910766602, mae:0.2027941793203354\n",
      "preds shape: (721, 24, 1)\n",
      "preds_2d shape: (17304, 1)\n",
      "trues shape: (721, 24, 1)\n",
      "trues_2d shape: (17304, 1)\n",
      "Inverse‐scaled mse:0.5446850715475058, mae:0.5606637084647111\n",
      "CSV saved → ./results/TEMPERATURE_WITHOUTLSTM_MS_2_FEDformer_random_modes64_custom_ftMS_sl24_ll24_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_'Exp'_0/pred_vs_true.csv | shape: (17304, 3)\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py --is_training 1 --root_path ./dataset/temperature/ --data_path temperature_dataset.csv --task_id TEMPERATURE_WITHOUTLSTM_MS_2 --model FEDformer --data custom --features MS --seq_len 24 --label_len 24 --pred_len 24 --e_layers 2 --d_layers 1 --factor 3 --enc_in 3 --dec_in 3 --c_out 3 --des 'Exp' --itr 1 --use_gpu True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
